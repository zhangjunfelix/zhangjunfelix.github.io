<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="noindex, nofollow">
<title>Rational Speech Act-learning notes | Jun Zhang</title>
<meta name="keywords" content="">
<meta name="description" content="&ldquo;&hellip; one of my avowed aims is to see talking as a special case or variety of purposive, indeed rational, behavior&rdquo; (Grice, 1975: 47)

I. Background of RSA
The Rational Speech Act (RSA) framework was developed within the broader enterprise of Probabilistic Pragmatics, a rapidly growing approach in the study of meaning.
Probabilistic pragmatics integrates insights from formal and experimental semantics and pragmatics, psycholinguistics, and computational cognitive science. It offers a unified framework for modeling how speakers produce and listeners interpret language in context.">
<meta name="author" content="">
<link rel="canonical" href="http://localhost:1313/tool/neuralnetworks/rsa/rsanotes/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.d6fcd20a4fb86efa4dfac8ec95da60244cc8871042183da1ef28e3a762ad79c8.css" integrity="sha256-1vzSCk&#43;4bvpN&#43;sjsldpgJEzIhxBCGD2h7yjjp2Ktecg=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:1313/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:1313/apple-touch-icon.png">
<link rel="mask-icon" href="http://localhost:1313/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="http://localhost:1313/tool/neuralnetworks/rsa/rsanotes/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" />
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
  onload="renderMathInElement(document.body, {
    delimiters: [
      {left: '$$', right: '$$', display: true},
      {left: '$', right: '$', display: false}
    ]
  });">
</script>

</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:1313/" accesskey="h" title="Jun Zhang (Alt + H)">Jun Zhang</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://localhost:1313/about/" title="About">
                    <span>About</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/projects/" title="Projects">
                    <span>Projects</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/teaching/" title="Teaching">
                    <span>Teaching</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/publications/" title="Publications">
                    <span>Publications</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/tool/" title="Toolbox">
                    <span>Toolbox</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      Rational Speech Act-learning notes
    </h1>
    <div class="post-meta"><span title='2025-05-06 11:41:54 -0400 EDT'>May 6, 2025</span>&nbsp;·&nbsp;51 min

</div>
  </header> <div class="toc">
    <details  open>
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#i-background-of-rsa">I. Background of RSA</a></li>
        <li><a href="#ii-classical-view-of-meaning-vs-rsa-view-of-meaning">II. classical view of meaning vs. RSA view of meaning</a></li>
        <li><a href="#iii-the-basicstandardvanilla-rsa-model">III. The basic/standard/vanilla RSA model</a></li>
        <li><a href="#iv-more-on-the-mathematical-notations-for-those-not-good-at-mathematical-formalization-like-me-you-may-find-it-a-bit-repetitive">IV. More on the mathematical notations (for those not good at mathematical formalization, like me) (you may find it a bit repetitive)</a></li>
        <li><a href="#41-denotation-function">4.1 Denotation Function</a></li>
        <li><a href="#42-literal-listener-l_0">4.2 Literal Listener $L_0$</a></li>
        <li><a href="#43-pragmatic-speaker--s_1-">4.3 Pragmatic Speaker $ S_1 $</a></li>
        <li><a href="#44-pragmatic-listener--l_1-">4.4 Pragmatic Listener $ L_1 $</a></li>
        <li><a href="#v-a-complete-illustration-of-pragmatic-reasoning-in-rsa">V. A complete illustration of pragmatic reasoning in RSA</a></li>
        <li><a href="#vi-reference-games">VI. Reference Games</a></li>
        <li><a href="#51-what-are-reference-games">5.1 What Are Reference Games?</a></li>
        <li><a href="#52-reference-games--formal-modeling">5.2 Reference Games — Formal Modeling</a></li>
        <li><a href="#54-literal-listener">5.4 Literal Listener</a></li>
        <li><a href="#55-pragmatic-speaker">5.5 Pragmatic Speaker</a></li>
        <li><a href="#56-pragmatic-listener">5.6 Pragmatic Listener</a></li>
        <li><a href="#extra">Extra</a></li>
        <li><a href="#extra-1-lambda-lambda">Extra #1 Lambda $\lambda$</a></li>
        <li><a href="#extra-2-softmax-function">Extra #2 Softmax Function</a></li>
        <li><a href="#extra-3-lambda-softmax-visualizer">Extra #3 Lambda Softmax Visualizer</a></li>
        <li><a href="#sources">Sources</a></li>
      </ul>
    </li>
  </ul>
</nav>
        </div>
    </details>
</div>

  <div class="post-content"><p>&ldquo;&hellip; one of my avowed aims is to see talking as a special case or variety of purposive, indeed rational, behavior&rdquo; (Grice, 1975: 47)</p>
<hr>
<h3 id="i-background-of-rsa">I. Background of RSA<a hidden class="anchor" aria-hidden="true" href="#i-background-of-rsa">#</a></h3>
<p>The Rational Speech Act (RSA) framework was developed within the broader enterprise of <strong>Probabilistic Pragmatics</strong>, a rapidly growing approach in the study of meaning.</p>
<p><strong>Probabilistic pragmatics</strong> integrates insights from formal and experimental semantics and pragmatics, psycholinguistics, and computational cognitive science. It offers a unified framework for modeling how speakers produce and listeners interpret language in context.</p>
<h4 id="key-characteristics-of-probabilistic-pragmatics">Key Characteristics of Probabilistic Pragmatics<a hidden class="anchor" aria-hidden="true" href="#key-characteristics-of-probabilistic-pragmatics">#</a></h4>
<ul>
<li><strong>Formal Framework</strong>: Provides a structure for implementing hypotheses about how speakers contextually choose among utterance alternatives and how listeners arrive at context-sensitive interpretations.</li>
<li><strong>Formalizing Conversational Principles</strong>: Captures principles such as relevance, brevity, and helpful informativeness (closely aligned with Gricean maxims) in a formal and testable way.</li>
<li><strong>Probabilistic Processes</strong>: Treats language production and interpretation as fundamentally probabilistic, allowing for <strong><em>gradience and variability</em></strong> that classic models struggle to explain.</li>
<li><strong>Bounded Rationality</strong>: Models speakers and listeners as boundedly rational agents, integrating information in ways consistent with general cognitive constraints.</li>
<li><strong>Integration of Factors</strong>: Allows linguistic knowledge to interact with communicative pressures and <strong>subjective prior beliefs</strong> (world knowledge), acknowledging their central role in interpretation.</li>
<li><strong>Bridging Theoretical Traditions</strong>: Seeks to unify &ldquo;language-as-product&rdquo; (representational structure) and &ldquo;language-as-action&rdquo; (context-sensitive decision-making).</li>
<li><strong>Methodology</strong>: Strongly computational and data-driven—models are implemented as algorithms and tested against empirical data.</li>
<li><strong>Contrast with Classic Views</strong>: In contrast to categorical interpretations in classic models, probabilistic pragmatics treats meaning, informativeness, and alternatives as <strong>gradient</strong> and <strong>context-dependent</strong>.</li>
</ul>
<h4 id="types-of-theories-within-probabilistic-pragmatics">Types of Theories within Probabilistic Pragmatics<a hidden class="anchor" aria-hidden="true" href="#types-of-theories-within-probabilistic-pragmatics">#</a></h4>
<ul>
<li><strong><em>Game-theoretic approaches</em></strong> (e.g., Benz &amp; Stevens, 2018)</li>
<li><strong><em>Probabilistic but not fully Bayesian accounts</em></strong> (e.g., Qing &amp; Franke, 2014; Russell, 2012)</li>
</ul>
<p>The <strong>Rational Speech Act (RSA)</strong> framework stands out as arguably the <strong>most influential probabilistic model of pragmatic interpretation</strong>, integrating many of the features described above.</p>
<h3 id="ii-classical-view-of-meaning-vs-rsa-view-of-meaning">II. classical view of meaning vs. RSA view of meaning<a hidden class="anchor" aria-hidden="true" href="#ii-classical-view-of-meaning-vs-rsa-view-of-meaning">#</a></h3>
<table>
  <thead>
      <tr>
          <th><strong>Aspect</strong></th>
          <th><strong>The Classic View of Meaning</strong></th>
          <th><strong>The RSA View of Meaning</strong></th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><strong>Nature of Interpretation</strong></td>
          <td>Meaning is treated as <strong>categorical</strong>. Implicatures either arise or not; presuppositions either project or not. No room for gradience or interpretational uncertainty.</td>
          <td>Interpretation is <strong>probabilistic</strong>. Listeners hold posterior probability distributions over meanings, capturing uncertainty. The model supports variability and gradience in interpretation.</td>
      </tr>
      <tr>
          <td><strong>Informativeness</strong></td>
          <td>Defined <strong>categorically</strong> using entailment-based alternatives. One statement is more informative if it entails another. No contextual modulation.</td>
          <td>Defined <strong>gradually</strong> and <strong>contextually</strong>. Informativeness reflects how much a literal listener would learn after hearing the utterance (minimizing surprisal). It varies based on the context.</td>
      </tr>
      <tr>
          <td><strong>Alternatives</strong></td>
          <td>Treated as <strong>static and lexicalized</strong> (e.g., scales like &lt;all, some&gt;). The set of alternatives is fixed and not derived from context.</td>
          <td>Treated as <strong>flexible and context-sensitive</strong>. RSA is not a theory of alternatives but a framework for testing hypotheses. Alternatives can be adjusted based on data, and costly or complex alternatives can be penalized.</td>
      </tr>
      <tr>
          <td><strong>World Knowledge (Prior Beliefs)</strong></td>
          <td><strong>Not integrated</strong>. Classic models often exclude prior beliefs or world knowledge from formal reasoning, viewing them as nonlinguistic.</td>
          <td><strong>Formally integrated</strong>. RSA uses Bayes’ rule to model how listeners use <strong>subjective prior beliefs</strong> (world knowledge) to infer intended meaning. These priors do not need to be objectively accurate.</td>
      </tr>
      <tr>
          <td><strong>Inference Process</strong></td>
          <td>Gricean reasoning involves fixed premises. If these are met, an implicature is derived categorically; if not, it doesn’t arise. The speaker is assumed to choose the stronger alternative if it is true.</td>
          <td>RSA models interpretation as a <strong>signaling game</strong>. The speaker selects utterances balancing informativeness and cost. The listener uses <strong>Bayesian inference</strong> over utterances, context, and prior beliefs. This allows for <strong>gradient</strong> and variable inference.</td>
      </tr>
  </tbody>
</table>
<h3 id="iii-the-basicstandardvanilla-rsa-model">III. The basic/standard/vanilla RSA model<a hidden class="anchor" aria-hidden="true" href="#iii-the-basicstandardvanilla-rsa-model">#</a></h3>
<p>The basic <strong>Rational Speech Act (RSA)</strong> model treats language use as a <strong>signaling game</strong>. Speakers and listeners are modeled as agents who reason about:</p>
<ul>
<li>a space of utterances: $ U $</li>
<li>a space of possible meanings: $ M $</li>
</ul>
<blockquote>
<p>What Is a Signaling Game?<br>
The RSA model builds on the idea that language use is a kind of <strong>signaling game</strong> — a concept borrowed from game theory (Lewis, 1969).<br>
A <strong>signaling game</strong> models communication as an interaction between two rational agents:</p>
<ul>
<li>A <strong>speaker</strong> (or sender) who wants to convey a particular meaning.</li>
<li>A <strong>listener</strong> (or receiver) who observes the speaker’s utterance and tries to infer what meaning was intended.</li>
</ul>
<p>Key Ingredients of a Signaling Game</p>
<table>
  <thead>
      <tr>
          <th>Role</th>
          <th>Description</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><strong>Sender</strong></td>
          <td>Knows some private information (e.g., a meaning) and sends a signal (utterance).</td>
      </tr>
      <tr>
          <td><strong>Signal</strong></td>
          <td>The utterance or message the speaker chooses to send.</td>
      </tr>
      <tr>
          <td><strong>Receiver</strong></td>
          <td>Observes the signal and makes an inference about the speaker’s intended meaning.</td>
      </tr>
      <tr>
          <td><strong>Goal</strong></td>
          <td>Successful communication: the listener correctly infers the speaker’s intended meaning.</td>
      </tr>
  </tbody>
</table>
</blockquote>
<h4 id="31-semantic-foundation-denotation-functions">3.1 Semantic Foundation (Denotation Functions)<a hidden class="anchor" aria-hidden="true" href="#31-semantic-foundation-denotation-functions">#</a></h4>
<p>RSA begins with a <strong>literal semantics</strong>, defined by a denotation function (see SECTION 4.1 for more explanations):</p>
<p>$$
\llbracket \cdot \rrbracket : U \rightarrow M
$$</p>
<p>This function specifies the set of meanings that are <strong>literally compatible</strong> with each utterance. It is assumed to be shared by both speaker and listener, grounding the recursive pragmatic reasoning that follows.</p>
<h4 id="32-recursive-probabilistic-rules">3.2 Recursive Probabilistic Rules<a hidden class="anchor" aria-hidden="true" href="#32-recursive-probabilistic-rules">#</a></h4>
<p>Building on literal semantics, RSA defines a <strong>recursive hierarchy</strong> of production and interpretation rules. These involve probabilistic reasoning at each level and encode pragmatic inference.</p>
<h4 id="33-literal-listener--p_l_0-">3.3 Literal Listener $ P_{L_0} $<a hidden class="anchor" aria-hidden="true" href="#33-literal-listener--p_l_0-">#</a></h4>
<p>The <strong>literal listener</strong> interprets utterances based on their literal meaning (See SECTION 4.2 for its components and calculations). Their interpretation rule is:</p>
<p>$$
P_{L_0}(m \mid u) = \delta_{m \in \llbracket u \rrbracket} \cdot P(m)
$$</p>
<p>This means the listener updates their prior beliefs $P(m)$
only for meanings that are <strong>literally compatible</strong> with the utterance <em>u</em>. Here, $ \delta_{m \in \llbracket u \rrbracket} $ is an indicator function that returns 1 if $ m \in \llbracket u \rrbracket $, and 0 otherwise.</p>
<p>This step enforces the <strong>Gricean Quality maxim</strong>, ruling out meanings that are literally false.</p>
<h4 id="34-pragmatic-speaker--p_s_1-">3.4 Pragmatic Speaker $\ P_{S_1} $<a hidden class="anchor" aria-hidden="true" href="#34-pragmatic-speaker--p_s_1-">#</a></h4>
<p>The <strong>pragmatic speaker</strong> reasons about the literal listener’s interpretation to choose an utterance that best conveys the intended meaning $m$ (See SECTION 4.3 for more details). The speaker is modeled as a utility-maximizing agent:</p>
<p>$$
P_{S_1}(u \mid m) \propto \exp\left(\alpha \cdot U(u, m)\right)
$$</p>
<p>The <strong>utility function</strong> balances informativeness and cost:</p>
<p>$$
U(u, m) = \log P_{L_0}(m \mid u) - \text{Cost}(u)
$$</p>
<ul>
<li><strong>Informativeness</strong>: How well $u$ communicates $m$, i.e., how likely the literal listener is to infer $m$.</li>
<li><strong>Cost</strong>: A penalty for utterances that are longer, less frequent, or harder to retrieve.</li>
<li><strong>α</strong> (alpha): A rationality parameter controlling how strongly the speaker optimizes utility.</li>
</ul>
<p>This step reflects <strong>Gricean Quantity</strong> (informativeness) and <strong>Manner</strong> (cost) maxims.</p>
<h4 id="35-pragmatic-listener--p_l_1">3.5 Pragmatic Listener  $P_{L_1}$<a hidden class="anchor" aria-hidden="true" href="#35-pragmatic-listener--p_l_1">#</a></h4>
<p>The <strong>pragmatic listener</strong> inverts the speaker model to infer the likely intended meaning:</p>
<p>$$
P_{L_1}(m \mid u) \propto P_{S_1}(u \mid m) \cdot P(m)
$$</p>
<p>This is a <strong>Bayesian inference</strong> over possible meanings, integrating:</p>
<ul>
<li>A model of the speaker’s utterance choice $ P_{S_1} $</li>
<li>The listener’s <strong>prior beliefs</strong> about likely meanings $ P(m) $</li>
</ul>
<p>These <strong>priors</strong> encode <strong>world knowledge</strong> and subjective expectations about communicative goals.</p>
<h4 id="key-insight">Key Insight<a hidden class="anchor" aria-hidden="true" href="#key-insight">#</a></h4>
<p>&ldquo;RSA models replace Grice&rsquo;s maxims with a single, utility-theoretic version of the cooperative principle&rdquo; (Goodman &amp; Frank, 2016: 821)</p>
<p>RSA treats language understanding as a <strong>probabilistic inference problem</strong>, in contrast to classical models which assume categorical interpretation. The pragmatic listener arrives at a <strong>posterior probability distribution</strong> over meanings, capturing the inherent uncertainty in language comprehension.</p>
<p>This recursive reasoning structure links production and interpretation in a unified, probabilistic framework.</p>
<h3 id="iv-more-on-the-mathematical-notations-for-those-not-good-at-mathematical-formalization-like-me-you-may-find-it-a-bit-repetitive">IV. More on the mathematical notations (for those not good at mathematical formalization, like me) (you may find it a bit repetitive)<a hidden class="anchor" aria-hidden="true" href="#iv-more-on-the-mathematical-notations-for-those-not-good-at-mathematical-formalization-like-me-you-may-find-it-a-bit-repetitive">#</a></h3>
<p>To facilitate the explanation, a Scalar Implicature Game is used as an example:</p>
<blockquote>
<p>BASIC SCALAR IMPLICATURE GAME
In this context, there were Alex and 4 cookies on a plate.<br>
Meaning space: $ M = \{ m_0, m_1, m_2, m_3, m_4 \} $</p>
<p>Utterance space: $ U = \{ u_{\text{all}}, u_{\text{some}}, u_{\text{none}} \} $</p>
<p>Semantics:  $ u_{\text{all}}  = \{ m_4 \}$</p>
<p>            $ u_{\text{some}}  = \{ m_1, m_2, m_3, m_4 \} $</p>
<p>            $ u_{\text{none}}  = \{ m_0 \} $</p>
<p>Prior beliefs: $P(m_0)$ = $P(m_1)$ = $P(m_2)$ = $P(m_3)$ = $P(m_4)$ = $0.2$</p>
</blockquote>
<h3 id="41-denotation-function">4.1 Denotation Function<a hidden class="anchor" aria-hidden="true" href="#41-denotation-function">#</a></h3>
<p>The <strong>denotation function</strong> is a foundational concept in formal semantics and the Rational Speech Act (RSA) framework. In the RSA framework, the <strong>denotation function</strong> is written as:</p>
<p>$$
\llbracket \cdot \rrbracket : U \rightarrow M
$$
This means:</p>
<blockquote>
<p>The denotation function <em>maps each utterance $ u $ from the set of possible utterances $ U $ to a set of meanings $ M $ — specifically, the meanings for which the utterance is <strong>literally true</strong></em>.</p>
</blockquote>
<h4 id="411--step-by-step-logic-of-the-indicator">4.1.1  Step-by-Step Logic of the Indicator<a hidden class="anchor" aria-hidden="true" href="#411--step-by-step-logic-of-the-indicator">#</a></h4>
<p>Step 1: Evaluate Whether $m$ Is Literally Compatible with $u$</p>
<ul>
<li>Ask: <em>Does this meaning make the utterance true according to its literal meaning?</em></li>
</ul>
<p>Step 2: Output the Result</p>
<ul>
<li>If <strong>YES</strong> → Output <strong>1</strong> (keep this meaning for further consideration).</li>
<li>If <strong>NO</strong> → Output <strong>0</strong> (eliminate this meaning from consideration).</li>
</ul>
<h4 id="412-meaning-of-components">4.1.2 Meaning of Components<a hidden class="anchor" aria-hidden="true" href="#412-meaning-of-components">#</a></h4>
<p>An <strong>utterance</strong> $ u $ is something a speaker might say.<br>
Example:</p>
<blockquote>
<p>“Alex ate some of the cookies.”</p>
</blockquote>
<p>A <strong>meaning</strong> $ m $ refers to a possible state of the world — what might be true or false.<br>
For example: (in a context where there were four cookies)</p>
<ul>
<li>$ m_0 $: Alex ate 0 cookie.</li>
<li>$ m_1 $: Alex ate 1 cookie.</li>
<li>$ m_2 $: Alex ate 2 cookies.</li>
<li>$ m_3 $: Alex ate 3 cookies.</li>
<li>$ m_4 $: Alex ate 4 cookies.</li>
</ul>
<p>These meanings represent different situations the utterance might refer to.</p>
<h4 id="413--what-does-the-denotation-function-do">4.1.3  What does the denotation function do?<a hidden class="anchor" aria-hidden="true" href="#413--what-does-the-denotation-function-do">#</a></h4>
<p>It defines which of those meanings ($m_0$, $m_1$, $m_2$, $m_3$, $m_4$) make the utterance <strong>literally true</strong>.</p>
<p>For the utterance:
$
u = \text{“Alex ate some of the cookies.”}
$</p>
<p>The denotation is:
$
\llbracket u \rrbracket = { m_1, m_2, m_3, m_4 }
$
, because the statement is true in those situations, but <strong>not</strong> in $\ m_{0} $, where Alex ate no cookies.</p>
<h4 id="414-why-is-this-important-in-rsa">4.1.4 Why Is This Important in RSA?<a hidden class="anchor" aria-hidden="true" href="#414-why-is-this-important-in-rsa">#</a></h4>
<ul>
<li>It directly enforces Grice’s <strong>Quality Maxim</strong> at the literal level: Only meanings that make the utterance literally true are considered.</li>
<li>It performs an efficient filtering step before any deeper probabilistic reasoning.</li>
<li>This grounding in literal truth ensures that <strong>pragmatic reasoning starts from a shared semantic base</strong>.</li>
<li>It makes the RSA framework <strong>compositional</strong> and <strong>grounded in literal semantics</strong>.</li>
</ul>
<h4 id="415-summary-table">4.1.5 Summary Table<a hidden class="anchor" aria-hidden="true" href="#415-summary-table">#</a></h4>
<table>
  <thead>
      <tr>
          <th>Concept</th>
          <th>Explanation</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>Utterance $ u $</td>
          <td>A sentence a speaker might say (“Some of the apples are red”)</td>
      </tr>
      <tr>
          <td>Meaning $ m $</td>
          <td>A possible state of the world (e.g., all red, some red, none red)</td>
      </tr>
      <tr>
          <td>Denotation $ \llbracket u \rrbracket $</td>
          <td>The set of meanings for which the utterance is literally true</td>
      </tr>
      <tr>
          <td>Role in RSA</td>
          <td>Helps the literal listener filter out meanings that are literally impossible</td>
      </tr>
  </tbody>
</table>
<hr>
<h3 id="42-literal-listener-l_0">4.2 Literal Listener $L_0$<a hidden class="anchor" aria-hidden="true" href="#42-literal-listener-l_0">#</a></h3>
<p>The <strong>Literal Listener</strong> — denoted as $L_0$ — interprets an utterance based solely on its <strong>literal semantics</strong>, without considering the speaker’s goals or alternative utterances.</p>
<h4 id="421-literal-listener-equations">4.2.1 Literal Listener Equations<a hidden class="anchor" aria-hidden="true" href="#421-literal-listener-equations">#</a></h4>
<h4 id="1-simplified-proportional-equation">1. Simplified (Proportional) Equation<a hidden class="anchor" aria-hidden="true" href="#1-simplified-proportional-equation">#</a></h4>
<p>$$
P_{L_0}(m \mid u) \propto \delta_{m \in \llbracket u \rrbracket} \cdot P(m)
$$</p>
<p>This means:</p>
<blockquote>
<p>The probability that the <strong>Literal Listener</strong> $L_0$ interprets utterance $u$ as meaning $m$ is proportional to whether the meaning $m$ is compatible with the literal semantics of $u$, multiplied by the prior probability of $ m $.</p>
</blockquote>
<ul>
<li>This computes <strong>unnormalized scores</strong>.</li>
</ul>
<h4 id="2-full-normalized-equation">2. Full Normalized Equation<a hidden class="anchor" aria-hidden="true" href="#2-full-normalized-equation">#</a></h4>
<p>$$
P_{L_0}(m \mid u) = \frac{\delta_{m \in \llbracket u \rrbracket} \cdot P(m)}{\displaystyle \sum_{m&rsquo;} \delta_{m&rsquo; \in \llbracket u \rrbracket} \cdot P(m&rsquo;)}
$$</p>
<ul>
<li>The denominator ensures that final probabilities <strong>sum to 1</strong>.</li>
<li>$\displaystyle \sum_{m&rsquo;}$ sums over all possible meanings $m&rsquo;$.</li>
</ul>
<p>NOTE:</p>
<blockquote>
<p>Denominator</p>
<p>$$
\sum_{m&rsquo;} \delta_{m&rsquo; \in \llbracket u \rrbracket} \cdot P(m&rsquo;)
$$</p>
<ul>
<li>This computes the total <strong>weight</strong> of all <strong>and only</strong> remaining possible meanings that make the utterance true (the meanings that make the utterance false would be <strong>left out</strong>).</li>
<li>It’s the sum over all possible meanings $ m&rsquo; $ that are <strong>compatible with the utterance</strong>.</li>
<li>This ensures the final probabilities <strong>sum to 1</strong> — this is the <strong>normalization step</strong>.</li>
</ul>
</blockquote>
<h4 id="why-are-there-two-versions">Why Are There Two Versions?<a hidden class="anchor" aria-hidden="true" href="#why-are-there-two-versions">#</a></h4>
<table>
  <thead>
      <tr>
          <th>Version</th>
          <th>Purpose</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>Proportional</td>
          <td>Computes unnormalized values. Useful for comparing relative likelihoods before normalization.</td>
      </tr>
      <tr>
          <td>Normalized</td>
          <td>Computes final, interpretable probabilities that sum to 1. Required for reporting and decision-making.</td>
      </tr>
  </tbody>
</table>
<h4 id="422-explanation-of-each-component">4.2.2 Explanation of Each Component<a hidden class="anchor" aria-hidden="true" href="#422-explanation-of-each-component">#</a></h4>
<p>(1) $ P_{L_0}(m \mid u) $<br>
This is the <strong>posterior belief</strong> of the Literal Listener:</p>
<blockquote>
<p>How likely is it that the intended meaning is $ m $, given that the utterance $ u $ was heard?</p>
</blockquote>
<p>This represents the listener’s literal interpretation of the utterance: $ \llbracket u \rrbracket $</p>
<p>(2) $ \llbracket u \rrbracket $</p>
<p>The set of meanings where $ u $ is literally true.</p>
<p>(3) $ \delta_{m \in \llbracket u \rrbracket} $</p>
<p>This is an <strong>indicator/delta function</strong>. It returns 1 if the meaning $m$ is <strong>compatible</strong> with the literal meaning of the utterance; 0 otherwise</p>
<blockquote>
<p>In effect, this acts as a <strong>truth filter</strong> — it rules out meanings that are not literally possible.</p>
</blockquote>
<p>(4) $ P(m) $</p>
<p>This is the <strong>prior probability</strong> of each possible meaning, representing the listener’s <strong>expectations</strong> about the world <strong>before</strong> hearing the utterance.</p>
<h4 id="423-how-the-literal-listener-computes-interpretation">4.2.3 How the Literal Listener Computes Interpretation<a hidden class="anchor" aria-hidden="true" href="#423-how-the-literal-listener-computes-interpretation">#</a></h4>
<p>In the RSA model, the <strong>Literal Listener</strong> $ L_0 $ updates beliefs about the world after hearing an utterance $ u $, based purely on <strong>literal semantics</strong> and <strong>prior expectations</strong>.</p>
<h4 id="example-1-alex-ate-some-of-the-cookies">Example 1: “Alex ate some of the cookies.”<a hidden class="anchor" aria-hidden="true" href="#example-1-alex-ate-some-of-the-cookies">#</a></h4>
<h4 id="step-1-define-the-possible-meanings-m">Step 1: Define the Possible Meanings $M$<a hidden class="anchor" aria-hidden="true" href="#step-1-define-the-possible-meanings-m">#</a></h4>
<table>
  <thead>
      <tr>
          <th>Meaning</th>
          <th>Description</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>$ m_0 $</td>
          <td>Alex ate 0 cookies</td>
      </tr>
      <tr>
          <td>$ m_1 $</td>
          <td>Alex ate 1 cookie</td>
      </tr>
      <tr>
          <td>$ m_2 $</td>
          <td>Alex ate 2 cookies</td>
      </tr>
      <tr>
          <td>$ m_3 $</td>
          <td>Alex ate 3 cookies</td>
      </tr>
      <tr>
          <td>$ m_4 $</td>
          <td>Alex ate 4 cookies</td>
      </tr>
  </tbody>
</table>
<p>Assume a <strong>uniform prior</strong>:</p>
<p>$$
P(m_i) = 0.2 \quad \text{for all } i \in {0, 1, 2, 3, 4}
$$</p>
<h4 id="step-2-determine-literal-semantics-define-llbracket-u-rrbracket">Step 2: Determine Literal Semantics (Define $\llbracket u \rrbracket$)<a hidden class="anchor" aria-hidden="true" href="#step-2-determine-literal-semantics-define-llbracket-u-rrbracket">#</a></h4>
<p>Utterance:</p>
<blockquote>
<p>$ u = $ &ldquo;Alex ate some of the cookies.&rdquo;</p>
</blockquote>
<p>Literal semantics:</p>
<p>$$
\llbracket u \rrbracket = { m_1, m_2, m_3, m_4 }
$$</p>
<h4 id="step-3">Step 3<a hidden class="anchor" aria-hidden="true" href="#step-3">#</a></h4>
<h4 id="option-1-calculation-using-the-simplified-proportional-equation">Option 1: Calculation Using the <strong>Simplified (Proportional) Equation</strong><a hidden class="anchor" aria-hidden="true" href="#option-1-calculation-using-the-simplified-proportional-equation">#</a></h4>
<p>$$
P_{L_0}(m \mid u) \propto \delta_{m \in \llbracket u \rrbracket} \cdot P(m)
$$</p>
<h4 id="compute-unnormalized-values">Compute Unnormalized Values:<a hidden class="anchor" aria-hidden="true" href="#compute-unnormalized-values">#</a></h4>
<!--$$
\delta_{m \in \llbracket u \rrbracket} = 
\begin{cases}
0 & \text{if } m = m_0 \\ 
1 & \text{if } m \in \{ m_1, m_2, m_3, m_4 \}
\end{cases}
$$ -->
<div align="center">
$$
\delta_{m \in \llbracket u \rrbracket} = 
\begin{cases}
0 & \text{if } m = m_0, \\
1 & \text{if } m \in \{ m_1, m_2, m_3, m_4 \}.
\end{cases}
$$
</div>
<ul>
<li>$P_{L_0}(m_0 \mid u) = \delta_{m_0 \in \llbracket u \rrbracket} \cdot P(m_0) = 0 \cdot 0.2 = 0$</li>
<li>$P_{L_0}(m_i \mid u) = \delta_{m_i \in \llbracket u \rrbracket} \cdot P(m_i) = 1 \cdot 0.2 = 0.2$  for $i \in {1, 2, 3, 4}$</li>
</ul>
<p>At this stage, these values are <strong>unnormalized scores</strong>.</p>
<h4 id="compute-the-denominator-when-you-normalize">Compute the Denominator When You Normalize<a hidden class="anchor" aria-hidden="true" href="#compute-the-denominator-when-you-normalize">#</a></h4>
<ul>
<li>The sum of unnormalized scores <strong>is the denominator</strong>:</li>
</ul>
<p>$$
\text{Denominator} = 0.2 + 0.2 + 0.2 + 0.2 = 0.8
$$</p>
<h4 id="final-step-normalize-to-get-probabilities"><strong>Final Step: Normalize to Get Probabilities</strong><a hidden class="anchor" aria-hidden="true" href="#final-step-normalize-to-get-probabilities">#</a></h4>
<p>$$
P_{L_0}(m_i \mid u) = \frac{\text{Unnormalized Score}}{\text{Denominator}} = \frac{0.2}{0.8} = 0.25 \quad \text{for } m_i \in {1, 2, 3, 4}
$$</p>
<h4 id="option-2-calculation-using-the-full-normalized-equation">Option 2: Calculation Using the Full Normalized Equation<a hidden class="anchor" aria-hidden="true" href="#option-2-calculation-using-the-full-normalized-equation">#</a></h4>
<p>$$
P_{L_0}(m \mid u) = \frac{\delta_{m \in \llbracket u \rrbracket} \cdot P(m)}{\displaystyle \sum_{m&rsquo;} \delta_{m&rsquo; \in \llbracket u \rrbracket} \cdot P(m&rsquo;)}
$$</p>
<h4 id="compute-numerators">Compute Numerators:<a hidden class="anchor" aria-hidden="true" href="#compute-numerators">#</a></h4>
<table>
  <thead>
      <tr>
          <th>Meaning</th>
          <th>$\delta_{m \in \llbracket u \rrbracket}$</th>
          <th>$P(m)$</th>
          <th>Numerator ($\delta \cdot P(m)$)</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>$m_0$</td>
          <td>0 (ruled out)</td>
          <td>0.2</td>
          <td>0</td>
      </tr>
      <tr>
          <td>$m_1$</td>
          <td>1</td>
          <td>0.2</td>
          <td>0.2</td>
      </tr>
      <tr>
          <td>$m_2$</td>
          <td>1</td>
          <td>0.2</td>
          <td>0.2</td>
      </tr>
      <tr>
          <td>$m_3$</td>
          <td>1</td>
          <td>0.2</td>
          <td>0.2</td>
      </tr>
      <tr>
          <td>$m_4$</td>
          <td>1</td>
          <td>0.2</td>
          <td>0.2</td>
      </tr>
  </tbody>
</table>
<h4 id="compute-denominator-normalization-constant">Compute Denominator (Normalization Constant):<a hidden class="anchor" aria-hidden="true" href="#compute-denominator-normalization-constant">#</a></h4>
<p>$$
\displaystyle \sum_{m&rsquo;} \delta_{m&rsquo; \in \llbracket u \rrbracket} \cdot P(m&rsquo;) = P(m_1) + P(m_2) + P(m_3) + P(m_4) = 0.2 + 0.2 + 0.2 + 0.2 = 0.8
$$</p>
<h4 id="compute-final-probabilities">Compute Final Probabilities:<a hidden class="anchor" aria-hidden="true" href="#compute-final-probabilities">#</a></h4>
<ul>
<li>For $m_0$ (ruled out):<br>
$$ P_{L_0}(m_0 \mid u) = 0 $$</li>
<li>For $m_i$ where $i \in {1, 2, 3, 4}$:<br>
$$ P_{L_0}(m_i \mid u) = \frac{0.2}{0.8} = 0.25 $$</li>
</ul>
<h4 id="final-interpretation">Final Interpretation<a hidden class="anchor" aria-hidden="true" href="#final-interpretation">#</a></h4>
<table>
  <thead>
      <tr>
          <th>Meaning</th>
          <th>Final Probability $P_{L_0}(m \mid u)$</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>$m_0$: 0 cookies</td>
          <td>0.0 (ruled out)</td>
      </tr>
      <tr>
          <td>$m_1$: 1 cookie</td>
          <td>0.25</td>
      </tr>
      <tr>
          <td>$m_2$: 2 cookies</td>
          <td>0.25</td>
      </tr>
      <tr>
          <td>$m_3$: 3 cookies</td>
          <td>0.25</td>
      </tr>
      <tr>
          <td>$m_4$: 4 cookies</td>
          <td>0.25</td>
      </tr>
  </tbody>
</table>
<hr>
<h4 id="example-2-alex-ate-none-of-the-cookies">Example 2: “Alex ate none of the cookies.”<a hidden class="anchor" aria-hidden="true" href="#example-2-alex-ate-none-of-the-cookies">#</a></h4>
<h4 id="step-1-define-the-possible-meanings-m-1">Step 1: Define the Possible Meanings $M$<a hidden class="anchor" aria-hidden="true" href="#step-1-define-the-possible-meanings-m-1">#</a></h4>
<table>
  <thead>
      <tr>
          <th>Meaning</th>
          <th>Description</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>$ m_0 $</td>
          <td>Alex ate 0 cookies</td>
      </tr>
      <tr>
          <td>$ m_1 $</td>
          <td>Alex ate 1 cookie</td>
      </tr>
      <tr>
          <td>$ m_2 $</td>
          <td>Alex ate 2 cookies</td>
      </tr>
      <tr>
          <td>$ m_3 $</td>
          <td>Alex ate 3 cookies</td>
      </tr>
      <tr>
          <td>$ m_4 $</td>
          <td>Alex ate 4 cookies</td>
      </tr>
  </tbody>
</table>
<p>Assume a <strong>uniform prior</strong>:</p>
<p>$$
P(m_i) = 0.2 \quad \text{for all } i \in {0, 1, 2, 3, 4}
$$</p>
<h4 id="step-2-determine-literal-semantics-define-llbracket-u-rrbracket-1">Step 2: Determine Literal Semantics (Define $\llbracket u \rrbracket$)<a hidden class="anchor" aria-hidden="true" href="#step-2-determine-literal-semantics-define-llbracket-u-rrbracket-1">#</a></h4>
<p>Utterance:</p>
<blockquote>
<p>$ u = $ &ldquo;Alex ate none of the cookies.&rdquo;</p>
</blockquote>
<p>Literal semantics:</p>
<p>$$
\llbracket u \rrbracket = { m_0 }
$$</p>
<h4 id="calculation-using-the-simplified-proportional-equation-option-1">Calculation Using the <strong>Simplified (Proportional) Equation</strong> (option 1)<a hidden class="anchor" aria-hidden="true" href="#calculation-using-the-simplified-proportional-equation-option-1">#</a></h4>
<p>$$
P_{L_0}(m \mid u) \propto \delta_{m \in \llbracket u \rrbracket} \cdot P(m)
$$</p>
<h4 id="compute-unnormalized-values-1">Compute Unnormalized Values:<a hidden class="anchor" aria-hidden="true" href="#compute-unnormalized-values-1">#</a></h4>
<table>
  <thead>
      <tr>
          <th>Meaning</th>
          <th>$\delta_{m \in \llbracket u \rrbracket}$</th>
          <th>$P(m)$</th>
          <th>Unnormalized Score</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>$m_0$</td>
          <td>1 (kept)</td>
          <td>0.2</td>
          <td>0.2</td>
      </tr>
      <tr>
          <td>$m_1$–$m_4$</td>
          <td>0 (ruled out)</td>
          <td>0.2</td>
          <td>0</td>
      </tr>
  </tbody>
</table>
<p>At this stage, the values are <strong>unnormalized scores</strong>.</p>
<h4 id="calculation-using-the-full-normalized-equation-option-2">Calculation Using the <strong>Full Normalized Equation</strong> (option 2)<a hidden class="anchor" aria-hidden="true" href="#calculation-using-the-full-normalized-equation-option-2">#</a></h4>
<p>$$
P_{L_0}(m \mid u) = \frac{\delta_{m \in \llbracket u \rrbracket} \cdot P(m)}{\displaystyle \sum_{m&rsquo;} \delta_{m&rsquo; \in \llbracket u \rrbracket} \cdot P(m&rsquo;)}
$$</p>
<h4 id="compute-the-denominator-normalization-constant">Compute the Denominator (Normalization Constant):<a hidden class="anchor" aria-hidden="true" href="#compute-the-denominator-normalization-constant">#</a></h4>
<p>$$
\text{Total} = P(m_0) = 0.2
$$</p>
<h4 id="compute-final-probabilities-1">Compute Final Probabilities:<a hidden class="anchor" aria-hidden="true" href="#compute-final-probabilities-1">#</a></h4>
<ul>
<li>For $m_0$:<br>
$$ P_{L_0}(m_0 \mid u) = \frac{0.2}{0.2} = 1.0 $$</li>
<li>For all other $m_i$:<br>
$$ P_{L_0}(m_i \mid u) = 0 \quad \text{for } i \in {1, 2, 3, 4} $$</li>
</ul>
<h4 id="final-interpretation-1">Final Interpretation<a hidden class="anchor" aria-hidden="true" href="#final-interpretation-1">#</a></h4>
<table>
  <thead>
      <tr>
          <th>Meaning</th>
          <th>Final Probability $P_{L_0}(m \mid u)$</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>$ m_0 $: 0 cookies</td>
          <td>1.0 (certain)</td>
      </tr>
      <tr>
          <td>$ m_1 $ to $ m_4 $</td>
          <td>0.0 (ruled out)</td>
      </tr>
  </tbody>
</table>
<hr>
<h4 id="example-3-alex-ate-all-of-the-cookies">Example 3: “Alex ate all of the cookies.”<a hidden class="anchor" aria-hidden="true" href="#example-3-alex-ate-all-of-the-cookies">#</a></h4>
<h4 id="step-1-define-the-possible-meanings-m-2">Step 1: Define the Possible Meanings $M$<a hidden class="anchor" aria-hidden="true" href="#step-1-define-the-possible-meanings-m-2">#</a></h4>
<table>
  <thead>
      <tr>
          <th>Meaning</th>
          <th>Description</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>$ m_0 $</td>
          <td>Alex ate 0 cookies</td>
      </tr>
      <tr>
          <td>$ m_1 $</td>
          <td>Alex ate 1 cookie</td>
      </tr>
      <tr>
          <td>$ m_2 $</td>
          <td>Alex ate 2 cookies</td>
      </tr>
      <tr>
          <td>$ m_3 $</td>
          <td>Alex ate 3 cookies</td>
      </tr>
      <tr>
          <td>$ m_4 $</td>
          <td>Alex ate 4 cookies</td>
      </tr>
  </tbody>
</table>
<p>Assume a <strong>uniform prior</strong>:</p>
<p>$$
P(m_i) = 0.2 \quad \text{for all } i \in {0, 1, 2, 3, 4}
$$</p>
<h4 id="step-2-determine-literal-semantics-define-llbracket-u-rrbracket-2">Step 2: Determine Literal Semantics (Define $\llbracket u \rrbracket$)<a hidden class="anchor" aria-hidden="true" href="#step-2-determine-literal-semantics-define-llbracket-u-rrbracket-2">#</a></h4>
<p>Utterance:</p>
<blockquote>
<p>$ u = $ &ldquo;Alex ate all of the cookies.&rdquo;</p>
</blockquote>
<p>Literal semantics:</p>
<p>$$
\llbracket u \rrbracket = { m_4 }
$$</p>
<h4 id="calculation-using-the-simplified-proportional-equation-option-1-1">Calculation Using the <strong>Simplified (Proportional) Equation</strong> (option 1)<a hidden class="anchor" aria-hidden="true" href="#calculation-using-the-simplified-proportional-equation-option-1-1">#</a></h4>
<p>$$
P_{L_0}(m \mid u) \propto \delta_{m \in \llbracket u \rrbracket} \cdot P(m)
$$</p>
<h4 id="compute-unnormalized-values-2">Compute Unnormalized Values<a hidden class="anchor" aria-hidden="true" href="#compute-unnormalized-values-2">#</a></h4>
<table>
  <thead>
      <tr>
          <th>Meaning</th>
          <th>$\delta_{m \in \llbracket u \rrbracket}$</th>
          <th>$P(m)$</th>
          <th>Unnormalized Score</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>$m_4$</td>
          <td>1 (kept)</td>
          <td>0.2</td>
          <td>0.2</td>
      </tr>
      <tr>
          <td>$m_0$–$m_3$</td>
          <td>0 (ruled out)</td>
          <td>0.2</td>
          <td>0</td>
      </tr>
  </tbody>
</table>
<p>At this stage, the values are <strong>unnormalized scores</strong>.</p>
<h4 id="calculation-using-the-full-normalized-equation-option-2-1">Calculation Using the <strong>Full Normalized Equation</strong> (option 2)<a hidden class="anchor" aria-hidden="true" href="#calculation-using-the-full-normalized-equation-option-2-1">#</a></h4>
<p>$$
P_{L_0}(m \mid u) = \frac{\delta_{m \in \llbracket u \rrbracket} \cdot P(m)}{\displaystyle \sum_{m&rsquo;} \delta_{m&rsquo; \in \llbracket u \rrbracket} \cdot P(m&rsquo;)}
$$</p>
<h4 id="compute-the-denominator-normalization-constant-1">Compute the Denominator (Normalization Constant):<a hidden class="anchor" aria-hidden="true" href="#compute-the-denominator-normalization-constant-1">#</a></h4>
<p>$$
\text{Total} = P(m_4) = 0.2
$$</p>
<h4 id="compute-final-probabilities-2">Compute Final Probabilities:<a hidden class="anchor" aria-hidden="true" href="#compute-final-probabilities-2">#</a></h4>
<ul>
<li>For $m_4$:<br>
$$ P_{L_0}(m_4 \mid u) = \frac{0.2}{0.2} = 1.0 $$</li>
<li>For all other $m_i$:<br>
$$ P_{L_0}(m_i \mid u) = 0 \quad \text{for } i \in {0, 1, 2, 3} $$</li>
</ul>
<h4 id="final-interpretation-2">Final Interpretation<a hidden class="anchor" aria-hidden="true" href="#final-interpretation-2">#</a></h4>
<table>
  <thead>
      <tr>
          <th>Meaning</th>
          <th></th>
          <th>Final Probability $P_{L_0}(m \mid u)$</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>$ m_4 $: 4 cookies</td>
          <td></td>
          <td>1.0 (certain)</td>
      </tr>
      <tr>
          <td>$ m_0 $ to $ m_3 $</td>
          <td></td>
          <td>0.0 (ruled out)</td>
      </tr>
  </tbody>
</table>
<ul>
<li>The simplified equation identifies that only $m_4$ is possible but doesn’t directly provide the final, normalized probability.</li>
<li>The full equation confirms that after normalization, the listener is <strong>completely certain</strong> the intended meaning is $m_4$.</li>
</ul>
<hr>
<h4 id="what-these-examples-show">What These Examples Show<a hidden class="anchor" aria-hidden="true" href="#what-these-examples-show">#</a></h4>
<table>
  <thead>
      <tr>
          <th>Utterance</th>
          <th>Remaining Possible Meanings</th>
          <th>Final Distribution</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>“Some”</td>
          <td>$ m_1 $ to $ m_4 $</td>
          <td>Evenly distributed (0.25 each)</td>
      </tr>
      <tr>
          <td>“None”</td>
          <td>$ m_0 $ only</td>
          <td>Certain (prob = 1)</td>
      </tr>
      <tr>
          <td>“All”</td>
          <td>$ m_4 $ only</td>
          <td>Certain (prob = 1)</td>
      </tr>
  </tbody>
</table>
<h4 id="423--a-more-detailed-example-based-on-the-full-equation-for-alex-ate-some-of-the-cookies">4.2.3  A more detailed example based on the full equation (for &ldquo;Alex ate some of the cookies.&rdquo;)<a hidden class="anchor" aria-hidden="true" href="#423--a-more-detailed-example-based-on-the-full-equation-for-alex-ate-some-of-the-cookies">#</a></h4>
<h4 id="what-are-m-and-m-in-the-literal-listener-formula">What Are $m$ and $m&rsquo;$ in the Literal Listener Formula?<a hidden class="anchor" aria-hidden="true" href="#what-are-m-and-m-in-the-literal-listener-formula">#</a></h4>
<p>$$
P_{L_0}(m \mid u) = \frac{\delta_{m \in \llbracket u \rrbracket} \cdot P(m)}{\displaystyle \sum_{m&rsquo;} \delta_{m&rsquo; \in \llbracket u \rrbracket} \cdot P(m&rsquo;)}
$$</p>
<table>
  <thead>
      <tr>
          <th>Symbol</th>
          <th>Meaning</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>$m$</td>
          <td>A <strong>specific possible meaning</strong> the listener is considering. Example: &ldquo;Alex ate 2 cookies.&rdquo;</td>
      </tr>
      <tr>
          <td>$m'$</td>
          <td>A <strong>placeholder variable</strong> for summing over <strong>all possible meanings</strong>.</td>
      </tr>
  </tbody>
</table>
<ul>
<li>The numerator computes the contribution of one particular meaning $m$.</li>
<li>The denominator sums over <strong>all meanings $m&rsquo;$</strong> to calculate the normalization constant.</li>
</ul>
<h4 id="example-alex-ate-some-of-the-cookies">Example: “Alex ate some of the cookies”<a hidden class="anchor" aria-hidden="true" href="#example-alex-ate-some-of-the-cookies">#</a></h4>
<h4 id="step-1-define-possible-meanings">Step 1: Define Possible Meanings<a hidden class="anchor" aria-hidden="true" href="#step-1-define-possible-meanings">#</a></h4>
<table>
  <thead>
      <tr>
          <th>Meaning</th>
          <th>Description</th>
          <th>Prior $P(m)$</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>$m_0$</td>
          <td>Alex ate 0 cookies</td>
          <td>0.2</td>
      </tr>
      <tr>
          <td>$m_1$</td>
          <td>Alex ate 1 cookie</td>
          <td>0.2</td>
      </tr>
      <tr>
          <td>$m_2$</td>
          <td>Alex ate 2 cookies</td>
          <td>0.2</td>
      </tr>
      <tr>
          <td>$m_3$</td>
          <td>Alex ate 3 cookies</td>
          <td>0.2</td>
      </tr>
      <tr>
          <td>$m_4$</td>
          <td>Alex ate 4 cookies</td>
          <td>0.2</td>
      </tr>
  </tbody>
</table>
<h4 id="step-2-determine-literal-semantics">Step 2: Determine Literal Semantics<a hidden class="anchor" aria-hidden="true" href="#step-2-determine-literal-semantics">#</a></h4>
<p>$$
\llbracket \text{“some”} \rrbracket = { m_1, m_2, m_3, m_4 }
$$</p>
<ul>
<li>“Some” means <strong>at least one cookie</strong> was eaten, so $m_0$ is ruled out.</li>
</ul>
<h4 id="step-3-compute-the-denominator-normalization">Step 3: Compute the Denominator (Normalization)<a hidden class="anchor" aria-hidden="true" href="#step-3-compute-the-denominator-normalization">#</a></h4>
<p>$$
\sum_{m&rsquo;} \delta_{m&rsquo; \in \llbracket u \rrbracket} \cdot P(m&rsquo;) = 1 * P(m_1) + 1 * P(m_2) + 1 * P(m_3) + 1 * P(m_4)
$$</p>
<p>$$
\text{Total} = 1 * 0.2 + 1 * 0.2 + 1 * 0.2 + 1 * 0.2 = 0.8
$$</p>
<h4 id="step-4-compute-final-probabilities-for-each-meaning">Step 4: Compute Final Probabilities for Each Meaning<a hidden class="anchor" aria-hidden="true" href="#step-4-compute-final-probabilities-for-each-meaning">#</a></h4>
<p>$$
P_{L_0}(m \mid u) = \frac{P(m)}{0.8} \quad \text{if } m \in \llbracket u \rrbracket
$$</p>
<table>
  <thead>
      <tr>
          <th>Meaning</th>
          <th>$P_{L_0}(m \mid u)$ Calculation</th>
          <th>Final Probability $P_{L_0}(m \mid u)$</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>$m_0$</td>
          <td>Ruled out by literal meaning</td>
          <td>0.0</td>
      </tr>
      <tr>
          <td>$m_1$</td>
          <td>$\frac{0.2}{0.8}$</td>
          <td>0.25</td>
      </tr>
      <tr>
          <td>$m_2$</td>
          <td>$\frac{0.2}{0.8}$</td>
          <td>0.25</td>
      </tr>
      <tr>
          <td>$m_3$</td>
          <td>$\frac{0.2}{0.8}$</td>
          <td>0.25</td>
      </tr>
      <tr>
          <td>$m_4$</td>
          <td>$\frac{0.2}{0.8}$</td>
          <td>0.25</td>
      </tr>
  </tbody>
</table>
<ul>
<li>$m$: The <strong>specific meaning</strong> you are evaluating.</li>
<li>$m&rsquo;$: The <strong>variable used to sum over all meanings</strong> during normalization.</li>
<li>The literal listener <strong>rules out incompatible meanings</strong> and redistributes prior beliefs over the remaining possibilities.</li>
</ul>
<h4 id="424-why-normalize">4.2.4 Why normalize?<a hidden class="anchor" aria-hidden="true" href="#424-why-normalize">#</a></h4>
<p>In the RSA model (and probabilistic modeling more broadly), <strong>normalization</strong> is the process of turning raw or unnormalized scores into a <strong>valid probability distribution</strong> — one where all values are between 0 and 1 and <strong>sum to exactly 1</strong>.</p>
<p>Probabilities must satisfy two conditions: (1) They must be <strong>non-negative</strong>; (2) They must <strong>sum to 1</strong>.</p>
<p>However, RSA agents (like the Literal Listener or Pragmatic Speaker) often compute values that are <strong>proportional to probabilities</strong>, not properly normalized. So we apply <strong>normalization</strong> to make them valid.</p>
<p>Normalization is needed whenever probabilities are defined <strong>up to proportionality</strong>.<br>
Normalization:</p>
<p>(1) Converts raw scores into valid probabilities<br>
(2) Filters and redistributes prior beliefs based on literal truth<br>
(3) Is essential for computing meaningful results in RSA and Bayesian models</p>
<p>It is the final — and often implicit — step in probabilistic interpretation.</p>
<h4 id="425--summary-table">4.2.5  Summary table<a hidden class="anchor" aria-hidden="true" href="#425--summary-table">#</a></h4>
<table>
  <thead>
      <tr>
          <th>Symbol</th>
          <th>Description</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>$ P_{L_0}(m \mid u) $</td>
          <td>Posterior belief about meaning $ m $ after hearing utterance $ u $</td>
      </tr>
      <tr>
          <td>$ \llbracket u \rrbracket $</td>
          <td>Literal denotation: set of meanings where $ u $ is true</td>
      </tr>
      <tr>
          <td>$ \delta_{m \in \llbracket u \rrbracket} $</td>
          <td>Truth filter: 1 if $ m $ is compatible with $ u $, else 0</td>
      </tr>
      <tr>
          <td>$ P(m) $</td>
          <td>Prior probability of each meaning $ m $</td>
      </tr>
  </tbody>
</table>
<p>The Literal Listener <strong>does not</strong> reason about why the speaker chose one utterance over another. It simply filters meanings based on:</p>
<ul>
<li>Literal truth conditions (defined by $ \llbracket u \rrbracket $)</li>
<li>Prior beliefs about what is likely</li>
</ul>
<p>This <strong>provides the foundation</strong> for higher levels of reasoning in RSA, where more sophisticated listeners and speakers reason about each other recursively.</p>
<hr>
<h3 id="43-pragmatic-speaker--s_1-">4.3 Pragmatic Speaker $ S_1 $<a hidden class="anchor" aria-hidden="true" href="#43-pragmatic-speaker--s_1-">#</a></h3>
<p>The <strong>Pragmatic Speaker</strong> (denoted as $ S_1 $) models the speaker as a <strong>rational agent</strong> who chooses utterances strategically. The speaker&rsquo;s goal is to:</p>
<ul>
<li>Communicate the intended meaning effectively (<strong>informativeness</strong>).</li>
<li>Minimize production effort or cost (<strong>cost</strong>).</li>
</ul>
<p>This balances the <strong>Gricean Quantity Maxim</strong> (be informative) and the <strong>Manner Maxim</strong> (avoid unnecessary effort).</p>
<h4 id="431-the-pragmatic-speaker-formula">4.3.1 The Pragmatic Speaker Formula<a hidden class="anchor" aria-hidden="true" href="#431-the-pragmatic-speaker-formula">#</a></h4>
<h4 id="1-simplified-proportional-equation-1">1. Simplified (Proportional) Equation<a hidden class="anchor" aria-hidden="true" href="#1-simplified-proportional-equation-1">#</a></h4>
<p>$$
P_{S_1}(u \mid m) \propto \exp \left( \alpha \cdot U(u, m) \right)
$$  where $ U(u, m) = \log P_{L_0}(m \mid u) - \text{cost}(u) $</p>
<p>This means:</p>
<blockquote>
<p>&ldquo;The probability that the <strong>Pragmatic Speaker</strong> $ S_1 $ will produce utterance $ u $ given that they want to communicate meaning $ m $, is proportional to the exponential of $ \alpha $ times the utility of utterance $ u $ for meaning $ m $.&rdquo;</p>
</blockquote>
<blockquote>
<p>This formula defines the speaker&rsquo;s production $ u $ as softmax optimizing $ u $&rsquo;s utility for communicating $ m $, $ U (u, m) $.</p>
</blockquote>
<p>Meaning of its components</p>
<ul>
<li>
<p>$ P_{S_1}(u \mid m) $: Probability the speaker chooses utterance $ u $ to communicate meaning $ m $.</p>
</li>
<li>
<p>$ \alpha $: Rationality parameter controlling how strongly the speaker optimizes utility.</p>
</li>
<li>
<p>$ U(u, m) $: Utility of utterance $ u $ for communicating meaning $ m $.</p>
</li>
<li>
<p><strong>$ \propto $</strong> is read as <strong>“proportional to”</strong>. It is used in equations to express that one quantity <strong>scales with another</strong>, but the exact value is not yet determined — because we still need to compute a normalization step.</p>
</li>
<li>
<p>This computes <strong>unnormalized scores</strong> for each utterance $u$.</p>
</li>
<li>
<p>$\alpha$ controls how strongly the speaker prefers higher-utility utterances.</p>
</li>
<li>
<p>$U(u, m)$ is the <strong>utility</strong> of utterance $u$ for conveying meaning $m$.</p>
</li>
</ul>
<h4 id="2-full-normalized-equation-softmax-function">2. Full Normalized Equation (Softmax Function)<a hidden class="anchor" aria-hidden="true" href="#2-full-normalized-equation-softmax-function">#</a></h4>
<p>$$
P_{S_1}(u \mid m) = \frac{\exp \left( \alpha \cdot U(u, m) \right)}{\displaystyle \sum_{u&rsquo;} \exp \left( \alpha \cdot U(u&rsquo;, m) \right)}
$$</p>
<ul>
<li>This computes the final probabilities by normalizing the unnormalized scores.</li>
<li>The denominator ensures that probabilities <strong>sum to 1</strong>.</li>
</ul>
<hr>
<h4 id="432-understanding-utility-uu-m">4.3.2 Understanding Utility $U(u, m)$<a hidden class="anchor" aria-hidden="true" href="#432-understanding-utility-uu-m">#</a></h4>
<p>The utility function balances <strong>informativeness</strong> and <strong>cost</strong>:</p>
<p>An utterance&rsquo;s utility $ U (u, m) $ is defined as a trade-off between the utterance&rsquo;s <strong>informativeness</strong> as characterized by $ P_{L_0}(m \mid u) $ &ndash;how likely it si that a lieral listener will corectly infer $ m $ from $ u $&rsquo;s literal semantics alone&ndash; and its cost, as defined in the utility function:</p>
<p>$$
U(u, m) = \log P_{L_0}(m \mid u) - \text{cost}(u)
$$</p>
<ul>
<li>$ \log P_{L_0}(m \mid u) $: <strong>Informativeness</strong> — how well the literal listener would infer $ m $ from $ u $.</li>
<li>$ \text{cost}(u) $: <strong>Cost</strong> of producing utterance $ u $ (e.g., effort, complexity, length).</li>
</ul>
<h4 id="how-does-this-work">How Does This Work?<a hidden class="anchor" aria-hidden="true" href="#how-does-this-work">#</a></h4>
<p>(1) <strong>Informativeness</strong>:</p>
<ul>
<li>The informativeness term captures the spirit of the Gricean Quantity Maxims (even Relation).</li>
<li>If the utterance makes the intended meaning very likely for the literal listener, its utility is high.</li>
<li>Example: “All the cookies were eaten” perfectly conveys the state where all cookies are gone.</li>
</ul>
<p>(2) <strong>Cost</strong>:</p>
<ul>
<li>The cost term captures the spirit of part of the Gricean Maxim of Mnner: the cheaper (e.g., shorter) the utterance, the better.</li>
<li>Longer or more complex utterances may have higher cost.</li>
<li>Example: “Alex ate all four cookies” might be costlier than simply saying “Alex ate all.”</li>
</ul>
<p>(3) <strong>Balancing</strong>:</p>
<ul>
<li>The pragmatic speaker prefers utterances that are <strong>informative but low in cost</strong>.</li>
<li>If two utterances are equally informative, the speaker prefers the cheaper one.</li>
</ul>
<h4 id="433-the-rationality-parameter-alpha">4.3.3 The Rationality Parameter $\alpha$<a hidden class="anchor" aria-hidden="true" href="#433-the-rationality-parameter-alpha">#</a></h4>
<ul>
<li>$ \alpha $ is a utlity-scaling parameter, which governs the extent to which the speaker is a utility-maximizing agent.</li>
<li>If $ \alpha = 0 $: The speaker chooses utterances <strong>randomly</strong>.</li>
<li>If $ \alpha = 1 $: The speaker chooses utterances <strong>proportionally to utility</strong> (probability matching).</li>
<li>If $ \alpha \to \infty $: The speaker ceases to choose utterances probabilistically and always chooses the <strong>utterance with the highest utility</strong> (fully rational).</li>
</ul>
<p>This softmax function makes the model flexible, allowing for varying levels of rationality in speaker behavior.</p>
<p>To compute pragmatic speaker probabilities, we must set a value for $ \alpha $ and define the cost of utterances.</p>
<table>
  <thead>
      <tr>
          <th>$\alpha$ Value</th>
          <th>Speaker Behavior</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>0</td>
          <td>Random utterance choice.</td>
      </tr>
      <tr>
          <td>1</td>
          <td>Probability matches utility.</td>
      </tr>
      <tr>
          <td>$\to \infty$</td>
          <td>Always chooses the utterance with the highest utility.</td>
      </tr>
  </tbody>
</table>
<h4 id="434-understanding-propto-and-why-normalize">4.3.4 Understanding $\propto$ and Why Normalize?<a hidden class="anchor" aria-hidden="true" href="#434-understanding-propto-and-why-normalize">#</a></h4>
<p><strong>$\propto$</strong> means <strong>“proportional to”</strong>.<br>
It indicates the values are relative but not yet normalized.</p>
<blockquote>
<p>The probability of choosing utterance $ u $ to express meaning $ m $ is <strong>proportional to</strong> the exponentiated utility, but this is <strong>not yet the final probability</strong>.</p>
</blockquote>
<h4 id="why-normalize">Why Normalize?<a hidden class="anchor" aria-hidden="true" href="#why-normalize">#</a></h4>
<ul>
<li>Probabilities must sum to <strong>1</strong>.</li>
<li>The full normalized equation ensures this by dividing unnormalized scores by their total sum.</li>
</ul>
<h4 id="435-worked-example-cookie-scenario">4.3.5 Worked Example: Cookie Scenario<a hidden class="anchor" aria-hidden="true" href="#435-worked-example-cookie-scenario">#</a></h4>
<p>Suppose the speaker wants to communicate that <strong>Alex ate all the cookies</strong>.</p>
<h4 id="step-1-compute-literal-listener-beliefs">Step 1: Compute Literal Listener Beliefs<a hidden class="anchor" aria-hidden="true" href="#step-1-compute-literal-listener-beliefs">#</a></h4>
<p>$$
P_{L_0}(m_4 \mid u_{\text{all}}) = 1.0, \quad P_{L_0}(m_4 \mid u_{\text{some}}) = 0.25
$$</p>
<h4 id="step-2-compute-utilities">Step 2: Compute Utilities<a hidden class="anchor" aria-hidden="true" href="#step-2-compute-utilities">#</a></h4>
<p>Assume $\text{cost}(u) = 0$ for simplicity.</p>
<ul>
<li>$U(u_{\text{all}}, m_4) = \log(1.0) = 0$</li>
<li>$U(u_{\text{some}}, m_4) = \log(0.25) \approx -1.386$</li>
</ul>
<h4 id="step-3-compute-unnormalized-scores-assume-alpha--1">Step 3: Compute Unnormalized Scores (Assume $\alpha = 1$)<a hidden class="anchor" aria-hidden="true" href="#step-3-compute-unnormalized-scores-assume-alpha--1">#</a></h4>
<ul>
<li>$P_{S_1}(u_{\text{all}} \mid m_4) \propto \exp(1 \cdot 0) = 1$</li>
<li>$P_{S_1}(u_{\text{some}} \mid m_4) \propto \exp(1 \cdot -1.386) \approx 0.25$</li>
</ul>
<h4 id="step-4-normalize">Step 4: Normalize<a hidden class="anchor" aria-hidden="true" href="#step-4-normalize">#</a></h4>
<p>$$
\text{Total} = 1 + 0.25 = 1.25
$$</p>
<ul>
<li>$P_{S_1}(u_{\text{all}} \mid m_4) = \frac{1}{1.25} = 0.8$</li>
<li>$P_{S_1}(u_{\text{some}} \mid m_4) = \frac{0.25}{1.25} = 0.2$</li>
</ul>
<h4 id="final-interpretation-3">Final Interpretation<a hidden class="anchor" aria-hidden="true" href="#final-interpretation-3">#</a></h4>
<table>
  <thead>
      <tr>
          <th>Utterance</th>
          <th>Final Probability $P_{S_1}(u \mid m_4)$</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>&ldquo;All&rdquo;</td>
          <td>0.8</td>
      </tr>
      <tr>
          <td>&ldquo;Some&rdquo;</td>
          <td>0.2</td>
      </tr>
  </tbody>
</table>
<ul>
<li>The speaker is <strong>four times more likely</strong> to say &ldquo;all&rdquo; than &ldquo;some&rdquo; when Alex ate all the cookies.</li>
</ul>
<h4 id="436-visualizing-speaker-behavior-figure-2">4.3.6 Visualizing Speaker Behavior (Figure 2)<a hidden class="anchor" aria-hidden="true" href="#436-visualizing-speaker-behavior-figure-2">#</a></h4>
<p align="center">
  <img src="/images/figure2Degen2023.png" alt="Figure 2: Pragmatic Speaker Production Probabilities" width="300px">
</p>
<ul>
<li><strong>Y-Axis</strong>: Probability of each utterance.</li>
<li><strong>X-Axis</strong>: Rationality parameter $\alpha$.</li>
<li>As $\alpha$ increases, the speaker increasingly prefers more informative utterances.</li>
</ul>
<h4 id="437-a-complete-example-cookies-scenario">4.3.7 A Complete Example: Cookies Scenario**<a hidden class="anchor" aria-hidden="true" href="#437-a-complete-example-cookies-scenario">#</a></h4>
<p><strong>Possible Meanings (M):</strong></p>
<ul>
<li>$ m_1 $: Alex ate <strong>all</strong> the cookies.</li>
<li>$ m_2 $: Alex ate <strong>some but not all</strong> cookies.</li>
<li>$ m_3 $: Alex ate <strong>none</strong> of the cookies.</li>
</ul>
<p><strong>Possible Utterances (U):</strong></p>
<ul>
<li>$ u_{\text{some}} $: “Alex ate some cookies.”</li>
<li>$ u_{\text{all}} $: “Alex ate all the cookies.”</li>
</ul>
<blockquote>
<h4 id="step-1-compute-literal-listeners-belief">Step 1: Compute Literal Listener’s Belief<a hidden class="anchor" aria-hidden="true" href="#step-1-compute-literal-listeners-belief">#</a></h4>
<p>Assume:</p>
<p>$$
P_{L_0}(m_1 \mid u_{\text{all}}) = 1.0,\quad P_{L_0}(m_1 \mid u_{\text{some}}) = 0.25
$$</p>
<p>This means:</p>
<ul>
<li>“All” perfectly communicates that Alex ate all cookies.</li>
<li>“Some” leaves uncertainty.</li>
</ul>
<h4 id="step-2-compute-utility">Step 2: Compute Utility<a hidden class="anchor" aria-hidden="true" href="#step-2-compute-utility">#</a></h4>
<p>Assume cost is zero for simplicity.</p>
<p>$$  U(u_{\text{all}}, m_1) = \log(1.0) = 0  $$</p>
<p>$$ U(u_{\text{some}}, m_1) = \log(0.25) = -1.386  $$</p>
<h4 id="step-3-compute-production-probabilities-assume--alpha--1-">Step 3: Compute Production Probabilities (Assume $ \alpha = 1 $)<a hidden class="anchor" aria-hidden="true" href="#step-3-compute-production-probabilities-assume--alpha--1-">#</a></h4>
<p>$$ P_{S_1}(u_{\text{all}} \mid m_1) \propto \exp(1 \cdot 0) = 1  $$</p>
<p>$$
P_{S_1}(u_{\text{some}} \mid m_1) \propto \exp(1 \cdot -1.386) \approx 0.25
$$</p>
<p>Normalize:</p>
<p>$$ P_{S_1}(u_{\text{all}} \mid m_1) = \frac{1}{1 + 0.25} = 0.8   $$
$$
P_{S_1}(u_{\text{some}} \mid m_1) = \frac{0.25}{1 + 0.25} = 0.2
$$</p>
<p><strong>Interpretation</strong>:</p>
<ul>
<li>The speaker is <strong>four times more likely</strong> to say “all” than “some” when Alex ate all cookies.</li>
</ul>
</blockquote>
<h4 id="438-how-to-understand-figure-2">4.3.8 How to understand Figure 2?<a hidden class="anchor" aria-hidden="true" href="#438-how-to-understand-figure-2">#</a></h4>
<h4 id="figure-2-rsa-speaker-production-probabilities"><strong>Figure 2: RSA Speaker Production Probabilities</strong><a hidden class="anchor" aria-hidden="true" href="#figure-2-rsa-speaker-production-probabilities">#</a></h4>
<p align="center">
  <img src="/images/figure2Degen2023.png" alt="Figure 2: Pragmatic Speaker Production Probabilities" width="300px">
</p>
<p>Figure 2 in Degen (2023) visualizes how the <strong>Pragmatic Speaker&rsquo;s production probabilities</strong> change as a function of the <strong>rationality parameter $\alpha$</strong>, assuming the intended meaning is that Alex ate all the cookies ($m_4$).</p>
<h4 id="rsa-model-equation-for-the-pragmatic-speaker">RSA Model Equation for the Pragmatic Speaker<a hidden class="anchor" aria-hidden="true" href="#rsa-model-equation-for-the-pragmatic-speaker">#</a></h4>
<p>$$
P_{S_1}(u \mid m) \propto \exp \left( \alpha \cdot U(u, m) \right)
$$</p>
<ul>
<li>$U(u, m)$ is the <strong>utility</strong> of utterance $u$ for expressing meaning $m$.</li>
<li>$\alpha$ controls how strongly the speaker favors high-utility utterances.</li>
</ul>
<h4 id="utility-calculation">Utility Calculation<a hidden class="anchor" aria-hidden="true" href="#utility-calculation">#</a></h4>
<p>$$
U(u, m) = \log P_{L_0}(m \mid u) - \text{cost}(u)
$$</p>
<ul>
<li>For the meaning $m_4$ (Alex ate all cookies):
<ul>
<li>$P_{L_0}(m_4 \mid u_{\text{all}}) = 1$ (perfectly informative)</li>
<li>$P_{L_0}(m_4 \mid u_{\text{some}}) = 0.25$ (less informative)</li>
</ul>
</li>
</ul>
<h4 id="how-to-read-the-figure">How to Read the Figure<a hidden class="anchor" aria-hidden="true" href="#how-to-read-the-figure">#</a></h4>
<ul>
<li><strong>Y-Axis</strong>: Probability of choosing each utterance ($P_{S_1}(u \mid m_4)$).</li>
<li><strong>X-Axis</strong>: Value of the rationality parameter $\alpha$.
<ul>
<li>Low $\alpha$: The speaker is less rational and chooses utterances almost randomly.</li>
<li>High $\alpha$: The speaker strongly prefers the more informative utterance (“all”).</li>
</ul>
</li>
</ul>
<p>As $\alpha$ increases, the model predicts the speaker will overwhelmingly prefer to say <strong>“all”</strong> rather than <strong>“some”</strong>.</p>
<hr>
<h4 id="what-this-demonstrates">What This Demonstrates<a hidden class="anchor" aria-hidden="true" href="#what-this-demonstrates">#</a></h4>
<ul>
<li>The figure shows the effect of the <strong>softmax function</strong>:<br>
Higher utilities lead to higher probabilities, but this relationship is smoothed and modulated by $\alpha$.</li>
<li>This accounts for graded, probabilistic behavior rather than hard, deterministic choices.</li>
<li>The RSA model predicts that humans adjust their speech behavior depending on context, goals, and cognitive resources (modeled by $\alpha$).</li>
</ul>
<h4 id="438-understanding-exp-in-the-pragmatic-speaker-equation">4.3.8 Understanding $\exp()$ in the Pragmatic Speaker Equation<a hidden class="anchor" aria-hidden="true" href="#438-understanding-exp-in-the-pragmatic-speaker-equation">#</a></h4>
<p>In the Pragmatic Speaker formula:</p>
<p>$$
P_{S_1}(u \mid m) \propto \exp\left( \alpha \cdot U(u, m) \right)
$$</p>
<p>The $\exp()$ function plays a critical role in transforming <strong>utilities into positive values</strong> suitable for computing probabilities.</p>
<hr>
<h4 id="what-does-exp-mean">What Does $\exp()$ Mean?<a hidden class="anchor" aria-hidden="true" href="#what-does-exp-mean">#</a></h4>
<ul>
<li>$\exp(x)$ is the <strong>exponential function</strong>, equivalent to $e^x$, where $e \approx 2.718$.</li>
<li>It converts utility values (which can be negative or positive) into <strong>positive scores</strong>.</li>
<li>This ensures that all computed scores for probabilities remain <strong>non-negative</strong>, which is required for valid probability calculations.</li>
</ul>
<hr>
<h4 id="why-use-exp">Why Use $\exp()$?<a hidden class="anchor" aria-hidden="true" href="#why-use-exp">#</a></h4>
<ol>
<li>
<p><strong>Transforms Utilities into Positive Scores</strong></p>
<ul>
<li>Since utilities can be negative, exponentiation ensures that all scores used for probability calculations are positive.</li>
</ul>
</li>
<li>
<p><strong>Amplifies Differences Between Utilities</strong></p>
<ul>
<li>Larger utilities result in exponentially larger scores, making higher-utility utterances significantly more likely.</li>
</ul>
</li>
<li>
<p><strong>Creates Smooth, Graded Probabilities (Softmax Function)</strong></p>
<ul>
<li>Even utterances with lower utility still have a non-zero chance of being selected, depending on the value of $\alpha$.</li>
</ul>
</li>
</ol>
<hr>
<h4 id="example-calculations">Example Calculations<a hidden class="anchor" aria-hidden="true" href="#example-calculations">#</a></h4>
<table>
  <thead>
      <tr>
          <th>Utility $U(u, m)$</th>
          <th>$\exp(U(u, m))$</th>
          <th>Interpretation</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>0</td>
          <td>1.0</td>
          <td>Baseline value.</td>
      </tr>
      <tr>
          <td>-1.386</td>
          <td>0.25</td>
          <td>Lower utility, lower score.</td>
      </tr>
      <tr>
          <td>2</td>
          <td>$\exp(2) \approx 7.389$</td>
          <td>High utility, very large score.</td>
      </tr>
  </tbody>
</table>
<hr>
<h4 id="key-takeaways">Key Takeaways<a hidden class="anchor" aria-hidden="true" href="#key-takeaways">#</a></h4>
<ul>
<li>$\exp()$ ensures that probabilities are <strong>positive and differentiable</strong>, enabling the use of softmax for probabilistic choices.</li>
<li>It reflects the intuition that the speaker is exponentially more likely to choose high-utility utterances, but not exclusively.</li>
<li>This function, combined with $\alpha$, controls how deterministic or probabilistic the speaker’s choices are.</li>
</ul>
<hr>
<h4 id="439-summary-table">4.3.9 Summary Table<a hidden class="anchor" aria-hidden="true" href="#439-summary-table">#</a></h4>
<table>
  <thead>
      <tr>
          <th>Component</th>
          <th>Meaning</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>$ P_{S_1}(u \mid m) $</td>
          <td>Speaker’s probability of choosing $ u $ given $ m $</td>
      </tr>
      <tr>
          <td>$ U(u, m) $</td>
          <td>Utility of utterance $ u $ for meaning $ m $</td>
      </tr>
      <tr>
          <td>$ \alpha $</td>
          <td>Rationality parameter controlling how deterministic the speaker is</td>
      </tr>
      <tr>
          <td>Cost $ \text{cost}(u) $</td>
          <td>Production effort or complexity of the utterance</td>
      </tr>
  </tbody>
</table>
<p>In sum, the pragmatic speaker chooses utterances strategically, balancing informativeness and cost. This formalization explains why speakers might sometimes <strong>avoid perfectly informative utterances</strong> when they are costly, or why they might <strong>choose simpler alternatives</strong> when the difference in informativeness is</p>
<hr>
<h3 id="44-pragmatic-listener--l_1-">4.4 Pragmatic Listener $ L_1 $<a hidden class="anchor" aria-hidden="true" href="#44-pragmatic-listener--l_1-">#</a></h3>
<p>The <strong>Pragmatic Listener</strong> in RSA, often denoted as $L_1$, performs <strong>Bayesian inference</strong> to reason about what meaning $m$ the speaker likely intended after hearing the utterance $u$.</p>
<p>This listener doesn&rsquo;t just rely on literal meaning; it also considers how likely the speaker would have chosen the utterance $u$ under each possible meaning $m$.</p>
<h4 id="441-equation-for-pragmatic-listener--l_1-">4.4.1 Equation for Pragmatic Listener $ L_1 $<a hidden class="anchor" aria-hidden="true" href="#441-equation-for-pragmatic-listener--l_1-">#</a></h4>
<h4 id="1-simplified-proportional-form"><strong>1. Simplified (Proportional) Form</strong><a hidden class="anchor" aria-hidden="true" href="#1-simplified-proportional-form">#</a></h4>
<p>$$
P_{L_1}(m \mid u) \propto P_{S_1}(u \mid m) \cdot P(m)
$$</p>
<ul>
<li>
<p>This tells us that the posterior belief about meaning $m$ is <strong>proportional</strong> to:</p>
<ul>
<li>The probability that the pragmatic speaker would choose $u$ to express $m$.</li>
<li>The prior probability of meaning $m$ before hearing the utterance.</li>
</ul>
</li>
<li>
<p>This equation computes <strong>unnormalized scores</strong>. To turn them into probabilities, we need to normalize.</p>
</li>
</ul>
<h4 id="2-full-normalized-equation-1"><strong>2. Full Normalized Equation</strong><a hidden class="anchor" aria-hidden="true" href="#2-full-normalized-equation-1">#</a></h4>
<p>$$
P_{L_1}(m \mid u) = \frac{P_{S_1}(u \mid m) \cdot P(m)}{\sum_{m&rsquo;} P_{S_1}(u \mid m&rsquo;) \cdot P(m&rsquo;)}
$$</p>
<ul>
<li>The denominator ensures that the final probabilities <strong>sum to 1</strong>.</li>
<li>$\sum_{m&rsquo;}$ sums over all possible meanings $m&rsquo;$.</li>
</ul>
<h4 id="explanation-of-components"><strong>Explanation of Components</strong><a hidden class="anchor" aria-hidden="true" href="#explanation-of-components">#</a></h4>
<table>
  <thead>
      <tr>
          <th>Component</th>
          <th>Explanation</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>$P_{L_1}(m \mid u)$</td>
          <td>The <strong>posterior probability</strong> that the intended meaning is $m$ after hearing utterance $u$.</td>
      </tr>
      <tr>
          <td>$P_{S_1}(u \mid m)$</td>
          <td>The <strong>pragmatic speaker’s probability</strong> of choosing utterance $u$ when intending meaning $m$. Computed via softmax over utilities.</td>
      </tr>
      <tr>
          <td>$P(m)$</td>
          <td>The <strong>prior probability</strong> of meaning $m$ before hearing any utterance (reflects world knowledge or expectations).</td>
      </tr>
      <tr>
          <td>Denominator (Normalization)</td>
          <td>Ensures the final probabilities sum to 1 by dividing by the total unnormalized probability mass.</td>
      </tr>
  </tbody>
</table>
<h4 id="how-does-this-work-conceptually"><strong>How Does This Work Conceptually?</strong><a hidden class="anchor" aria-hidden="true" href="#how-does-this-work-conceptually">#</a></h4>
<ol>
<li>
<p>The listener hears $u$ and asks:</p>
<blockquote>
<p><em>“How likely would a rational speaker have said this if they intended each possible meaning?”</em></p>
</blockquote>
</li>
<li>
<p>The listener also considers how likely each meaning was <strong>before</strong> hearing $u$ (using the prior $P(m)$).</p>
</li>
<li>
<p>Combining these two factors, the listener updates their beliefs and computes the final probabilities over meanings.</p>
</li>
</ol>
<h4 id="why-are-there-two-versions-of-the-equation"><strong>Why Are There Two Versions of the Equation?</strong><a hidden class="anchor" aria-hidden="true" href="#why-are-there-two-versions-of-the-equation">#</a></h4>
<table>
  <thead>
      <tr>
          <th>Version</th>
          <th>Purpose</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>Proportional</td>
          <td>Used to calculate relative likelihoods before normalization. Efficient for intermediate steps.</td>
      </tr>
      <tr>
          <td>Normalized</td>
          <td>Produces valid probabilities that sum to 1. Required for final interpretation and reporting results.</td>
      </tr>
  </tbody>
</table>
<h4 id="442-case-study-scalar-implicature-for-some-likelihood-of-m_4-being-true-when-u_textsome-is-heard">4.4.2 Case Study: Scalar Implicature for &ldquo;Some&rdquo; (Likelihood of $m_4$ being true when $u_{\text{some}}$ is heard)<a hidden class="anchor" aria-hidden="true" href="#442-case-study-scalar-implicature-for-some-likelihood-of-m_4-being-true-when-u_textsome-is-heard">#</a></h4>
<ul>
<li>
<p><strong>Utterance space</strong>:<br>
$U = { u_{\text{all}}, u_{\text{some}}, u_{\text{none}} }$</p>
</li>
<li>
<p><strong>Possible meanings</strong>:<br>
$M = { m_0, m_1, m_2, m_3, m_4 }$</p>
<ul>
<li>$m_0$: Alex ate 0 cookies</li>
<li>$m_1$: Alex ate 1 cookie</li>
<li>$m_2$: Alex ate 2 cookies</li>
<li>$m_3$: Alex ate 3 cookies</li>
<li>$m_4$: Alex ate all 4 cookies</li>
</ul>
</li>
<li>
<p>Assume a <strong>uniform prior</strong>:<br>
$P(m_i) = 0.2$ for all $i$.</p>
</li>
<li>
<p>Utterance heard:<br>
$u = u_{\text{some}}$ (&ldquo;Alex ate some of the cookies.&rdquo;)</p>
</li>
</ul>
<h4 id="step-1-compute-the-pragmatic-speakers-probabilities-of-choosing-an-utterance-when-m_4-is-true-p_s_1u-mid-m_4">Step 1: Compute the Pragmatic Speaker’s Probabilities of choosing an utterance when $m_4$ is true [$P_{S_1}(u \mid m_4)$]<a hidden class="anchor" aria-hidden="true" href="#step-1-compute-the-pragmatic-speakers-probabilities-of-choosing-an-utterance-when-m_4-is-true-p_s_1u-mid-m_4">#</a></h4>
<h4 id="literal-listeners-interpretations">Literal Listener’s Interpretations:<a hidden class="anchor" aria-hidden="true" href="#literal-listeners-interpretations">#</a></h4>
<p><strong>For $u_{\text{all}}$</strong></p>
<ul>
<li>$P_{L_0}(m_4 \mid u_{\text{all}}) = \delta_{m_4 \in \llbracket u_{\text{all}} \rrbracket} \cdot P(m_4) = 1 \cdot 0.2 = 0.2 $ (This is Unnormalized probability)</li>
</ul>
<p>Normalization Step</p>
<p>$$
\sum_{m&rsquo;} \delta_{m&rsquo; \in \llbracket u_{\text{all}} \rrbracket} \cdot P(m&rsquo;) = P(m_4) = 0.2
$$</p>
<p>Final probability:</p>
<p>$$
P_{L_0}(m_4 \mid u_{\text{all}}) = \frac{0.2}{0.2} = 1.0
$$</p>
<blockquote>
<blockquote>
<p>Step-by-Step Expansion</p>
</blockquote>
</blockquote>
<ul>
<li>
<p>Recall that $\llbracket u_{\text{all}} \rrbracket = { m_4 }$, because the utterance &ldquo;all&rdquo; is only literally true if Alex ate all the cookies.</p>
</li>
<li>
<p>So the indicator function $\delta_{m&rsquo; \in \llbracket u_{\text{all}} \rrbracket}$ evaluates as:</p>
</li>
</ul>
<table>
  <thead>
      <tr>
          <th>$m'$</th>
          <th>$\delta_{m&rsquo; \in \llbracket u_{\text{all}} \rrbracket}$</th>
          <th>$P(m&rsquo;)$</th>
          <th>Contribution</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>$m_0$</td>
          <td>0 (ruled out)</td>
          <td>0.2</td>
          <td>$0 \cdot 0.2 = 0$</td>
      </tr>
      <tr>
          <td>$m_1$</td>
          <td>0 (ruled out)</td>
          <td>0.2</td>
          <td>$0 \cdot 0.2 = 0$</td>
      </tr>
      <tr>
          <td>$m_2$</td>
          <td>0 (ruled out)</td>
          <td>0.2</td>
          <td>$0 \cdot 0.2 = 0$</td>
      </tr>
      <tr>
          <td>$m_3$</td>
          <td>0 (ruled out)</td>
          <td>0.2</td>
          <td>$0 \cdot 0.2 = 0$</td>
      </tr>
      <tr>
          <td>$m_4$</td>
          <td>1 (kept)</td>
          <td>0.2</td>
          <td>$1 \cdot 0.2 = 0.2$</td>
      </tr>
  </tbody>
</table>
<ul>
<li>Summing all contributions:</li>
</ul>
<p>$$
\text{Total} = 0 + 0 + 0 + 0 + 0.2 = 0.2
$$</p>
<p><strong>For $u_{\text{some}}$</strong></p>
<ul>
<li>$P_{L_0}(m_4 \mid u_{\text{some}}) = 0.25$</li>
</ul>
<hr>
<h4 id="utility-calculation-1">Utility Calculation:<a hidden class="anchor" aria-hidden="true" href="#utility-calculation-1">#</a></h4>
<p>Using $U(u, m) = \log P_{L_0}(m \mid u)$ and assuming no cost:</p>
<ul>
<li>$U(u_{\text{all}}, m_4) = \log(1) = 0$</li>
<li>$U(u_{\text{some}}, m_4) = \log(0.25) \approx -1.386$</li>
</ul>
<h4 id="compute-p_s_1u-mid-m_4">Compute $P_{S_1}(u \mid m_4)$:<a hidden class="anchor" aria-hidden="true" href="#compute-p_s_1u-mid-m_4">#</a></h4>
<ul>
<li>
<p>Unnormalized:</p>
<ul>
<li>$P_{S_1}(u_{\text{all}} \mid m_4) \propto \exp(0) = 1$</li>
<li>$P_{S_1}(u_{\text{some}} \mid m_4) \propto \exp(-1.386) \approx 0.25$</li>
</ul>
</li>
<li>
<p>Normalize:</p>
<ul>
<li>Total = $1 + 0.25 = 1.25$</li>
<li>$P_{S_1}(u_{\text{all}} \mid m_4) = \frac{1}{1.25} = 0.8$</li>
<li>$P_{S_1}(u_{\text{some}} \mid m_4) = \frac{0.25}{1.25} = 0.2$</li>
</ul>
</li>
</ul>
<h4 id="step-2-compute-the-pragmatic-listeners-posterior-p_l_1m-mid-u_textsome">Step 2: Compute the Pragmatic Listener’s Posterior $P_{L_1}(m \mid u_{\text{some}})$<a hidden class="anchor" aria-hidden="true" href="#step-2-compute-the-pragmatic-listeners-posterior-p_l_1m-mid-u_textsome">#</a></h4>
<p>Apply Bayes’ Rule:</p>
<p>$$
P_{L_1}(m \mid u_{\text{some}}) \propto P_{S_1}(u_{\text{some}} \mid m) \cdot P(m)
$$</p>
<p>Compute unnormalized scores for all meanings:</p>
<table>
  <thead>
      <tr>
          <th>Meaning</th>
          <th>$P_{S_1}(u_{\text{some}} \mid m)$</th>
          <th>$P(m)$</th>
          <th>Product</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>$m_0$</td>
          <td>0 (ruled out by literal meaning)</td>
          <td>0.2</td>
          <td>0.0</td>
      </tr>
      <tr>
          <td>$m_1$</td>
          <td>Assume 0.4</td>
          <td>0.2</td>
          <td>0.08</td>
      </tr>
      <tr>
          <td>$m_2$</td>
          <td>Assume 0.3</td>
          <td>0.2</td>
          <td>0.06</td>
      </tr>
      <tr>
          <td>$m_3$</td>
          <td>Assume 0.2</td>
          <td>0.2</td>
          <td>0.04</td>
      </tr>
      <tr>
          <td>$m_4$</td>
          <td>0.2 (computed above)</td>
          <td>0.2</td>
          <td>0.04</td>
      </tr>
  </tbody>
</table>
<p>Total sum = $0.08 + 0.06 + 0.04 + 0.04 = 0.22$</p>
<h4 id="final-posterior-probabilities">Final Posterior Probabilities:<a hidden class="anchor" aria-hidden="true" href="#final-posterior-probabilities">#</a></h4>
<table>
  <thead>
      <tr>
          <th>Meaning</th>
          <th>Final $P_{L_1}(m \mid u_{\text{some}})$</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>$m_0$</td>
          <td>0.0 (ruled out)</td>
      </tr>
      <tr>
          <td>$m_1$</td>
          <td>$\frac{0.08}{0.22} \approx 0.364$</td>
      </tr>
      <tr>
          <td>$m_2$</td>
          <td>$\frac{0.06}{0.22} \approx 0.273$</td>
      </tr>
      <tr>
          <td>$m_3$</td>
          <td>$\frac{0.04}{0.22} \approx 0.182$</td>
      </tr>
      <tr>
          <td>$m_4$</td>
          <td>$\frac{0.04}{0.22} \approx 0.182$</td>
      </tr>
  </tbody>
</table>
<h4 id="interpretation"><strong>Interpretation</strong><a hidden class="anchor" aria-hidden="true" href="#interpretation">#</a></h4>
<ul>
<li>After hearing &ldquo;some of the cookies were eaten,&rdquo; the listener assigns the highest probability to $m_1$ (Alex ate only 1 cookie).</li>
<li>Although $m_4$ is possible, it’s less likely because if Alex had eaten all the cookies, the speaker would have likely said “all” instead.</li>
<li>This demonstrates how the RSA model formally derives the <strong>scalar implicature</strong> that “some” often implies “not all.”</li>
</ul>
<hr>
<h3 id="v-a-complete-illustration-of-pragmatic-reasoning-in-rsa">V. A complete illustration of pragmatic reasoning in RSA<a hidden class="anchor" aria-hidden="true" href="#v-a-complete-illustration-of-pragmatic-reasoning-in-rsa">#</a></h3>
<p>This section, building on the previous sections, offers a complete demonstration of how listensers interpret scalar utterances, like &ldquo;Alex ate some of the cookies.&rdquo;</p>
<h4 id="common-setup-and-assumptions">Common Setup and Assumptions<a hidden class="anchor" aria-hidden="true" href="#common-setup-and-assumptions">#</a></h4>
<table>
  <thead>
      <tr>
          <th>Meaning</th>
          <th>Description</th>
          <th>Prior $P(m)$</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>$m_0$</td>
          <td>Alex ate 0 cookies</td>
          <td>0.2</td>
      </tr>
      <tr>
          <td>$m_1$</td>
          <td>Alex ate 1 cookie</td>
          <td>0.2</td>
      </tr>
      <tr>
          <td>$m_2$</td>
          <td>Alex ate 2 cookies</td>
          <td>0.2</td>
      </tr>
      <tr>
          <td>$m_3$</td>
          <td>Alex ate 3 cookies</td>
          <td>0.2</td>
      </tr>
      <tr>
          <td>$m_4$</td>
          <td>Alex ate 4 cookies</td>
          <td>0.2</td>
      </tr>
  </tbody>
</table>
<p>Utterance space:</p>
<p>$$
U = { u_{\text{none}}, u_{\text{some}}, u_{\text{all}} }
$$</p>
<p>Literal Semantics:</p>
<ul>
<li>$\llbracket u_{\text{none}} \rrbracket = { m_0 }$</li>
<li>$\llbracket u_{\text{some}} \rrbracket = { m_1, m_2, m_3, m_4 }$</li>
<li>$\llbracket u_{\text{all}} \rrbracket = { m_4 }$</li>
</ul>
<p>Assume <strong>$\alpha = 1$</strong> and <strong>$\text{cost}(u) = 0$</strong> for all utterances.</p>
<h4 id="reasoning-level-1-literal-listener-l_0">REASONING LEVEL #1 <strong>Literal Listener ($L_0$)</strong><a hidden class="anchor" aria-hidden="true" href="#reasoning-level-1-literal-listener-l_0">#</a></h4>
<h4 id="step-1-apply-the-full-equation">Step 1: Apply the Full Equation<a hidden class="anchor" aria-hidden="true" href="#step-1-apply-the-full-equation">#</a></h4>
<p>$$
P_{L_0}(m \mid u_{\text{some}}) = \frac{\delta_{m \in \llbracket u_{\text{some}} \rrbracket} \cdot P(m)}{\displaystyle \sum_{m&rsquo;} \delta_{m&rsquo; \in \llbracket u_{\text{some}} \rrbracket} \cdot P(m&rsquo;)}
$$</p>
<p>Compute Denominator:</p>
<p>$$
\text{Total} = 0.2 + 0.2 + 0.2 + 0.2 = 0.8
$$</p>
<p>Compute Final Probabilities:</p>
<ul>
<li>$P_{L_0}(m_0 \mid u_{\text{some}}) = 0$</li>
<li>$P_{L_0}(m_i \mid u_{\text{some}}) = \frac{0.2}{0.8} = 0.25$ for $i \in {1, 2, 3, 4}$</li>
</ul>
<h4 id="l_0-final-belief-distribution">$L_0$ Final Belief Distribution<a hidden class="anchor" aria-hidden="true" href="#l_0-final-belief-distribution">#</a></h4>
<table>
  <thead>
      <tr>
          <th>Meaning</th>
          <th>$P_{L_0}(m \mid u_{\text{some}})$</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>$m_0$</td>
          <td>0.0 (ruled out)</td>
      </tr>
      <tr>
          <td>$m_1$</td>
          <td>0.25</td>
      </tr>
      <tr>
          <td>$m_2$</td>
          <td>0.25</td>
      </tr>
      <tr>
          <td>$m_3$</td>
          <td>0.25</td>
      </tr>
      <tr>
          <td>$m_4$</td>
          <td>0.25</td>
      </tr>
  </tbody>
</table>
<h4 id="reasoning-level-2-pragmatic-speaker-s_1">REASONING LEVEL #2 <strong>Pragmatic Speaker ($S_1$)</strong><a hidden class="anchor" aria-hidden="true" href="#reasoning-level-2-pragmatic-speaker-s_1">#</a></h4>
<p>The speaker reasons about how the Literal Listener interprets utterances to decide which utterance to produce.</p>
<h4 id="step-1-compute-utility-for-each-utterance-when-meaning--m_4">Step 1: Compute Utility for Each Utterance When Meaning = $m_4$<a hidden class="anchor" aria-hidden="true" href="#step-1-compute-utility-for-each-utterance-when-meaning--m_4">#</a></h4>
<p>Using:</p>
<p>$$
U(u, m) = \log P_{L_0}(m \mid u) - \text{cost}(u)
$$</p>
<table>
  <thead>
      <tr>
          <th>Utterance</th>
          <th>$P_{L_0}(m_4 \mid u)$</th>
          <th>$U(u, m_4)$</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>$u_{\text{all}}$</td>
          <td>1.0</td>
          <td>$\log(1) = 0$</td>
      </tr>
      <tr>
          <td>$u_{\text{some}}$</td>
          <td>0.25</td>
          <td>$\log(0.25) = -1.386$</td>
      </tr>
      <tr>
          <td>$u_{\text{none}}$</td>
          <td>0 (ruled out)</td>
          <td>$-\infty$</td>
      </tr>
  </tbody>
</table>
<h4 id="step-2-compute-unnormalized-scores">Step 2: Compute Unnormalized Scores<a hidden class="anchor" aria-hidden="true" href="#step-2-compute-unnormalized-scores">#</a></h4>
<p>$$
P_{S_1}(u \mid m_4) \propto \exp\left( \alpha \cdot U(u, m_4) \right)
$$</p>
<table>
  <thead>
      <tr>
          <th>Utterance</th>
          <th>$\exp(\alpha \cdot U)$</th>
          <th>Unnormalized Score</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>$u_{\text{all}}$</td>
          <td>$\exp(0) = 1$</td>
          <td>1.0</td>
      </tr>
      <tr>
          <td>$u_{\text{some}}$</td>
          <td>$\exp(-1.386) \approx 0.25$</td>
          <td>0.25</td>
      </tr>
      <tr>
          <td>$u_{\text{none}}$</td>
          <td>0</td>
          <td>0</td>
      </tr>
  </tbody>
</table>
<p>Total Sum = $1 + 0.25 = 1.25$</p>
<h4 id="step-3-normalize-to-get-final-speaker-probabilities">Step 3: Normalize to Get Final Speaker Probabilities<a hidden class="anchor" aria-hidden="true" href="#step-3-normalize-to-get-final-speaker-probabilities">#</a></h4>
<ul>
<li>$P_{S_1}(u_{\text{all}} \mid m_4) = \frac{1}{1.25} = 0.8$</li>
<li>$P_{S_1}(u_{\text{some}} \mid m_4) = \frac{0.25}{1.25} = 0.2$</li>
</ul>
<h4 id="s_1-final-production-probabilities-given-m_4">$S_1$ Final Production Probabilities (Given $m_4$)<a hidden class="anchor" aria-hidden="true" href="#s_1-final-production-probabilities-given-m_4">#</a></h4>
<table>
  <thead>
      <tr>
          <th>Utterance</th>
          <th>$P_{S_1}(u \mid m_4)$</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>&ldquo;All&rdquo;</td>
          <td>0.8</td>
      </tr>
      <tr>
          <td>&ldquo;Some&rdquo;</td>
          <td>0.2</td>
      </tr>
      <tr>
          <td>&ldquo;None&rdquo;</td>
          <td>0</td>
      </tr>
  </tbody>
</table>
<h4 id="reasoning-level-3-pragmatic-listener-l_1">REASONING LEVEL #3 <strong>Pragmatic Listener ($L_1$)</strong><a hidden class="anchor" aria-hidden="true" href="#reasoning-level-3-pragmatic-listener-l_1">#</a></h4>
<p>The listener now reasons about what meaning the speaker most likely intended after hearing the utterance.</p>
<h4 id="step-1-apply-the-full-equation-1">Step 1: Apply the Full Equation<a hidden class="anchor" aria-hidden="true" href="#step-1-apply-the-full-equation-1">#</a></h4>
<p>$$
P_{L_1}(m \mid u_{\text{some}}) = \frac{P_{S_1}(u_{\text{some}} \mid m) \cdot P(m)}{\displaystyle \sum_{m&rsquo;} P_{S_1}(u_{\text{some}} \mid m&rsquo;) \cdot P(m&rsquo;)}
$$</p>
<h4 id="step-2-compute-p_s_1u_textsome-mid-m-for-all-meanings">Step 2: Compute $P_{S_1}(u_{\text{some}} \mid m)$ for All Meanings<a hidden class="anchor" aria-hidden="true" href="#step-2-compute-p_s_1u_textsome-mid-m-for-all-meanings">#</a></h4>
<p>We already computed this for $m_4$:</p>
<ul>
<li>$P_{S_1}(u_{\text{some}} \mid m_4) = 0.2$</li>
</ul>
<p>Assume for this example:</p>
<table>
  <thead>
      <tr>
          <th>Meaning</th>
          <th>$P_{S_1}(u_{\text{some}} \mid m)$</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>$m_0$</td>
          <td>0 (ruled out by literal semantics)</td>
      </tr>
      <tr>
          <td>$m_1$</td>
          <td>0.4</td>
      </tr>
      <tr>
          <td>$m_2$</td>
          <td>0.3</td>
      </tr>
      <tr>
          <td>$m_3$</td>
          <td>0.2</td>
      </tr>
      <tr>
          <td>$m_4$</td>
          <td>0.2</td>
      </tr>
  </tbody>
</table>
<h4 id="step-3-compute-numerator-and-denominator">Step 3: Compute Numerator and Denominator<a hidden class="anchor" aria-hidden="true" href="#step-3-compute-numerator-and-denominator">#</a></h4>
<table>
  <thead>
      <tr>
          <th>Meaning</th>
          <th>$P_{S_1}(u_{\text{some}} \mid m)$</th>
          <th>$P(m)$</th>
          <th>Product</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>$m_0$</td>
          <td>0</td>
          <td>0.2</td>
          <td>0</td>
      </tr>
      <tr>
          <td>$m_1$</td>
          <td>0.4</td>
          <td>0.2</td>
          <td>0.08</td>
      </tr>
      <tr>
          <td>$m_2$</td>
          <td>0.3</td>
          <td>0.2</td>
          <td>0.06</td>
      </tr>
      <tr>
          <td>$m_3$</td>
          <td>0.2</td>
          <td>0.2</td>
          <td>0.04</td>
      </tr>
      <tr>
          <td>$m_4$</td>
          <td>0.2</td>
          <td>0.2</td>
          <td>0.04</td>
      </tr>
  </tbody>
</table>
<p>Denominator (Normalization Constant):<br>
$$
\text{Total} = 0.08 + 0.06 + 0.04 + 0.04 = 0.22
$$</p>
<h4 id="step-4-compute-final-l_1-posterior-beliefs">Step 4: Compute Final $L_1$ Posterior Beliefs<a hidden class="anchor" aria-hidden="true" href="#step-4-compute-final-l_1-posterior-beliefs">#</a></h4>
<ul>
<li>$P_{L_1}(m_1 \mid u_{\text{some}}) = \frac{0.08}{0.22} \approx 0.364$</li>
<li>$P_{L_1}(m_2 \mid u_{\text{some}}) = \frac{0.06}{0.22} \approx 0.273$</li>
<li>$P_{L_1}(m_3 \mid u_{\text{some}}) = \frac{0.04}{0.22} \approx 0.182$</li>
<li>$P_{L_1}(m_4 \mid u_{\text{some}}) = \frac{0.04}{0.22} \approx 0.182$</li>
<li>$P_{L_1}(m_0 \mid u_{\text{some}}) = 0$</li>
</ul>
<h4 id="l_1-final-interpretation">$L_1$ Final Interpretation<a hidden class="anchor" aria-hidden="true" href="#l_1-final-interpretation">#</a></h4>
<table>
  <thead>
      <tr>
          <th>Meaning</th>
          <th>$P_{L_1}(m \mid u_{\text{some}})$</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>$m_0$: 0 cookies</td>
          <td>0.0 (ruled out)</td>
      </tr>
      <tr>
          <td>$m_1$: 1 cookie</td>
          <td>0.364</td>
      </tr>
      <tr>
          <td>$m_2$: 2 cookies</td>
          <td>0.273</td>
      </tr>
      <tr>
          <td>$m_3$: 3 cookies</td>
          <td>0.182</td>
      </tr>
      <tr>
          <td>$m_4$: 4 cookies</td>
          <td>0.182</td>
      </tr>
  </tbody>
</table>
<h4 id="overall-takeaways"><strong>Overall Takeaways</strong><a hidden class="anchor" aria-hidden="true" href="#overall-takeaways">#</a></h4>
<table>
  <thead>
      <tr>
          <th>Agent</th>
          <th>Main Process</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>$L_0$</td>
          <td>Filters meanings based on literal truth.</td>
      </tr>
      <tr>
          <td>$S_1$</td>
          <td>Chooses utterances to maximize utility.</td>
      </tr>
      <tr>
          <td>$L_1$</td>
          <td>Infers intended meaning based on the utterance and speaker model.</td>
      </tr>
  </tbody>
</table>
<ul>
<li>Each level of reasoning in the RSA model refines the interpretation process using both <strong>prior knowledge</strong> and <strong>rational inference</strong>.</li>
</ul>
<hr>
<h3 id="vi-reference-games">VI. Reference Games<a hidden class="anchor" aria-hidden="true" href="#vi-reference-games">#</a></h3>
<p>This section presents how RSA explains language production and comprehension in Reference Games based on Franke &amp; Jäger (2016).</p>
<h3 id="51-what-are-reference-games">5.1 What Are Reference Games?<a hidden class="anchor" aria-hidden="true" href="#51-what-are-reference-games">#</a></h3>
<p><strong>Reference Games</strong> are simplified experimental tasks designed to study how speakers choose expressions to refer to objects and how listeners interpret those expressions.</p>
<h4 id="key-features-of-reference-games">Key Features of Reference Games<a hidden class="anchor" aria-hidden="true" href="#key-features-of-reference-games">#</a></h4>
<ul>
<li><strong>Interactive Setting</strong>: Involves a speaker and a listener.</li>
<li><strong>Goal</strong>:
<ul>
<li>The speaker must communicate a specific referent (target object) to the listener.</li>
<li>The listener must infer which object the speaker is referring to based on the utterance.</li>
</ul>
</li>
</ul>
<h4 id="typical-experimental-setup">Typical Experimental Setup<a hidden class="anchor" aria-hidden="true" href="#typical-experimental-setup">#</a></h4>
<p>Here is an example:</p>
<p align="center">
  <img src="/images/referencegameexample.png" alt="Reference Game Example" width="600px">
</p>
<ul>
<li>
<p>Objects in Context:<br>
Example:</p>
<ul>
<li>Green Square</li>
<li>Green Circle</li>
<li>Blue Circle</li>
</ul>
</li>
<li>
<p>Possible Utterances:</p>
<ul>
<li>&ldquo;green&rdquo;</li>
<li>&ldquo;square&rdquo;</li>
<li>&ldquo;circle&rdquo;</li>
<li>&ldquo;blue&rdquo;</li>
</ul>
</li>
</ul>
<p>Task:<br>
<strong>If the target is the <em>Green Square</em>, should the speaker say &ldquo;green&rdquo; or &ldquo;square&rdquo;?</strong><br>
- &ldquo;Square&rdquo; is more <strong>informative</strong> because it uniquely identifies the referent.</p>
<h4 id="connection-to-gricean-maxims">Connection to Gricean Maxims<a hidden class="anchor" aria-hidden="true" href="#connection-to-gricean-maxims">#</a></h4>
<ul>
<li>
<p><strong>Maxim of Quantity</strong>: Be as informative as required.<br>
→ Speakers prefer utterances that best help the listener identify the referent.</p>
</li>
<li>
<p><strong>Maxim of Manner</strong>: Avoid unnecessary effort.<br>
→ Speakers also tend to avoid overly complex or costly expressions.</p>
</li>
</ul>
<h4 id="what-makes-reference-games-powerful">What Makes Reference Games Powerful?<a hidden class="anchor" aria-hidden="true" href="#what-makes-reference-games-powerful">#</a></h4>
<ul>
<li>They provide a simple, controlled environment for testing:
<ul>
<li>How speakers balance <strong>informativeness</strong> and <strong>production cost</strong>.</li>
<li>How listeners reason about speaker choices (<strong>pragmatic inference</strong>).</li>
</ul>
</li>
<li>Reference games form the foundation for formal models of language use like the <strong>RSA model</strong>.</li>
</ul>
<h3 id="52-reference-games--formal-modeling">5.2 Reference Games — Formal Modeling<a hidden class="anchor" aria-hidden="true" href="#52-reference-games--formal-modeling">#</a></h3>
<p>In this section, we explore how the RSA model accounts for reasoning in reference games, following the mathematical formalizations used in <strong>Franke &amp; Jäger (2016)</strong>.</p>
<h4 id="1-literal-listener-l_0">1. Literal Listener ($L_0$)<a hidden class="anchor" aria-hidden="true" href="#1-literal-listener-l_0">#</a></h4>
<p>$$
P_{\text{literal}}(r \mid p) =
\begin{cases}
\frac{1}{|{r&rsquo; : p \text{ is true of } r&rsquo;}|} &amp; \text{if } p \text{ is true of } r \\
0 &amp; \text{otherwise}
\end{cases}
$$</p>
<ul>
<li>This assigns <strong>uniform probability</strong> over all referents that literally satisfy the utterance.</li>
<li>The Literal Listener does <strong>not</strong> consider why the speaker chose this utterance—only whether it’s true of a referent.</li>
</ul>
<h4 id="explanation-of-formula-components">Explanation of Formula Components<a hidden class="anchor" aria-hidden="true" href="#explanation-of-formula-components">#</a></h4>
<ul>
<li>
<p>$r$: Referent (target object)</p>
</li>
<li>
<p>$p$: Property or utterance</p>
</li>
<li>
<p>${ r&rsquo; : p \text{ is true of } r&rsquo; }$<br>
→ This is the <strong>set of all referents</strong> for which the property $p$ holds true.<br>
<em>Example</em>: If $p$ is &ldquo;green&rdquo;, this set contains all green objects.</p>
</li>
<li>
<p>$|{ r&rsquo; : p \text{ is true of } r&rsquo; }|$<br>
→ This is the <strong>size of that set</strong>, i.e., how many referents have the property $p$.</p>
</li>
<li>
<p>$\frac{1}{|{ \dots }|}$<br>
→ This means that <strong>each compatible referent is assigned equal probability</strong>, based on the total number of compatible referents.</p>
</li>
<li>
<p>$\text{if } p \text{ is true of } r$<br>
→ This part of the case condition says that the formula only applies if $r$ is actually compatible with the utterance $p$.</p>
</li>
</ul>
<h4 id="what-does-r-represent">What Does $r&rsquo;$ Represent?<a hidden class="anchor" aria-hidden="true" href="#what-does-r-represent">#</a></h4>
<table>
  <thead>
      <tr>
          <th>Symbol</th>
          <th>Meaning</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>$r$</td>
          <td>The specific referent the listener is considering.</td>
      </tr>
      <tr>
          <td>$r'$</td>
          <td>A variable representing <strong>all possible referents</strong> in the context. Used for counting how many referents are compatible with the utterance.</td>
      </tr>
  </tbody>
</table>
<ul>
<li>The notation ${ r&rsquo; : p \text{ is true of } r&rsquo; }$ defines the set of <strong>all referents where the utterance $p$ is literally true</strong>.</li>
<li>The term $| \dots |$ counts how many referents are in that set.</li>
</ul>
<blockquote>
<h4 id="example-listener-hears-green"><strong>Example: Listener Hears “green”</strong><a hidden class="anchor" aria-hidden="true" href="#example-listener-hears-green">#</a></h4>
<table>
  <thead>
      <tr>
          <th>Referent</th>
          <th>Properties</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>$r_1$</td>
          <td>Green, Square</td>
      </tr>
      <tr>
          <td>$r_2$</td>
          <td>Green, Circle</td>
      </tr>
      <tr>
          <td>$r_3$</td>
          <td>Blue, Circle</td>
      </tr>
  </tbody>
</table>
<ul>
<li>${ r&rsquo; : p = \text{&ldquo;green&rdquo;} \text{ is true of } r&rsquo; } = { r_1, r_2 }$</li>
<li>$|{ \dots }| = 2$</li>
</ul>
<h4 id="compute-probabilities">Compute Probabilities:<a hidden class="anchor" aria-hidden="true" href="#compute-probabilities">#</a></h4>
<ul>
<li>$P_{\text{literal}}(r_1 \mid \text{&ldquo;green&rdquo;}) = \frac{1}{2} = 0.5$</li>
<li>$P_{\text{literal}}(r_2 \mid \text{&ldquo;green&rdquo;}) = 0.5$</li>
<li>$P_{\text{literal}}(r_3 \mid \text{&ldquo;green&rdquo;}) = 0$</li>
</ul>
</blockquote>
<h4 id="2-pragmatic-speaker-s_1">2. Pragmatic Speaker ($S_1$)<a hidden class="anchor" aria-hidden="true" href="#2-pragmatic-speaker-s_1">#</a></h4>
<p>$$
P_{prod}(p \mid r; \lambda, f) =
\frac{\exp\left(\lambda \cdot EU_{speaker}(r, p; f)\right)}{\sum_{p&rsquo;} \exp\left(\lambda \cdot EU_{speaker}(r, p&rsquo;; f)\right)}
$$</p>
<ul>
<li>$ EU_{speaker}(r, p; f) = P_{literal}(r \mid p) + f(p) $</li>
<li>$f(p)$: Utterance bias or cost</li>
<li>$\lambda$: Rationality parameter (inverse temperature)</li>
</ul>
<h4 id="3-pragmatic-listener-l_1">3. Pragmatic Listener ($L_1$)<a hidden class="anchor" aria-hidden="true" href="#3-pragmatic-listener-l_1">#</a></h4>
<p>$$
P_{\text{comp}}(r \mid p) = \frac{P(r) \cdot P_{\text{prod}}(p \mid r)}{\sum_{r&rsquo;} P(r&rsquo;) \cdot P_{\text{prod}}(p \mid r&rsquo;)}
$$</p>
<h4 id="53-further-break-downs-of-the-mathematical-notations-in-franke--jager-2016-and-degen-2023">5.3 Further break-downs of the mathematical notations in Franke &amp; Jager (2016) and Degen (2023)<a hidden class="anchor" aria-hidden="true" href="#53-further-break-downs-of-the-mathematical-notations-in-franke--jager-2016-and-degen-2023">#</a></h4>
<h4 id="literal-listener-notation-comparison">Literal Listener: Notation Comparison<a hidden class="anchor" aria-hidden="true" href="#literal-listener-notation-comparison">#</a></h4>
<table>
  <thead>
      <tr>
          <th>Concept</th>
          <th>Franke &amp; Jäger (2016)</th>
          <th>Degen (2023)</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>Agent</td>
          <td>$P_{\text{literal}}(r \mid p)$</td>
          <td>$P_{L_0}(m \mid u)$</td>
      </tr>
      <tr>
          <td>Meaning / Referent</td>
          <td>$r$ = referent</td>
          <td>$m$ = meaning</td>
      </tr>
      <tr>
          <td>Utterance</td>
          <td>$p$ = property</td>
          <td>$u$ = utterance</td>
      </tr>
      <tr>
          <td>Literal Semantics</td>
          <td>$p$ is true of $r$</td>
          <td>$m \in \llbracket u \rrbracket$</td>
      </tr>
      <tr>
          <td>Truth Filter</td>
          <td>Verbal condition</td>
          <td>Indicator: $\delta_{m \in \llbracket u \rrbracket}$</td>
      </tr>
      <tr>
          <td>Uniformity</td>
          <td>Uniform over compatible referents</td>
          <td>Prior $P(m)$ allows non-uniformity</td>
      </tr>
      <tr>
          <td>Normalization</td>
          <td>Divide by number of compatible referents</td>
          <td>Sum over priors of compatible meanings</td>
      </tr>
  </tbody>
</table>
<h4 id="key-takeaways-1">Key Takeaways<a hidden class="anchor" aria-hidden="true" href="#key-takeaways-1">#</a></h4>
<ul>
<li>Both formulations implement literal semantics: they restrict attention to meanings that are literally compatible with the utterance.</li>
<li>Degen’s version allows more <strong>Bayesian flexibility</strong> and incorporates <strong>world knowledge via priors</strong>.</li>
<li>Franke &amp; Jäger’s approach is useful for <strong>simple reference tasks</strong> with uniform assumptions.</li>
</ul>
<h3 id="54-literal-listener">5.4 Literal Listener<a hidden class="anchor" aria-hidden="true" href="#54-literal-listener">#</a></h3>
<p><em>(Based on Franke &amp; Jäger, 2016)</em></p>
<h4 id="step-1-understand-the-task-setup">Step 1: Understand the Task Setup<a hidden class="anchor" aria-hidden="true" href="#step-1-understand-the-task-setup">#</a></h4>
<table>
  <thead>
      <tr>
          <th>Object</th>
          <th>Color</th>
          <th>Shape</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>$r_1$</td>
          <td>Green</td>
          <td>Square</td>
      </tr>
      <tr>
          <td>$r_2$</td>
          <td>Green</td>
          <td>Cirle</td>
      </tr>
      <tr>
          <td>$r_3$</td>
          <td>Blue</td>
          <td>Circle</td>
      </tr>
  </tbody>
</table>
<p><em>Possible Utterances (Properties)</em>:</p>
<p>$p \in \{ &ldquo;green&rdquo;, &ldquo;circle&rdquo;, &ldquo;square&rdquo;, &ldquo;blue&rdquo; \}$</p>
<h4 id="how-does-the-literal-listener-interpret-an-utterance">How Does the Literal Listener Interpret an Utterance?<a hidden class="anchor" aria-hidden="true" href="#how-does-the-literal-listener-interpret-an-utterance">#</a></h4>
<p>The Literal Listener reasons <strong>purely based on literal semantics</strong>, without considering why the speaker chose a particular utterance.</p>
<h4 id="formula">Formula:<a hidden class="anchor" aria-hidden="true" href="#formula">#</a></h4>
<p>$$
P_{\text{literal}}(r \mid p) =
\begin{cases}
\frac{1}{|{ r&rsquo; : p \text{ is true of } r&rsquo; }|} &amp; \text{if } p \text{ is true of } r \\
0 &amp; \text{otherwise}
\end{cases}
$$</p>
<ul>
<li>If the utterance $p$ is true of object $r$, assign <strong>equal probability</strong> among all such objects.</li>
<li>Otherwise, assign probability $0$.</li>
</ul>
<h4 id="example-1-listener-hears-green">Example 1: Listener Hears “green”<a hidden class="anchor" aria-hidden="true" href="#example-1-listener-hears-green">#</a></h4>
<ol>
<li>
<p>Determine which objects that are compatible with the property &ldquo;green&rdquo;:<br>
→ $r_1$ (Green Square), $r_2$ (Green Circle)</p>
</li>
<li>
<p>Assign Probabilities:</p>
<table>
  <thead>
      <tr>
          <th>Referent</th>
          <th>Compatible with &ldquo;green&rdquo;?</th>
          <th>$P_{\text{literal}}(r \mid p = \text{&ldquo;green&rdquo;})$</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>$r_1$</td>
          <td>Yes</td>
          <td>0.5</td>
      </tr>
      <tr>
          <td>$r_2$</td>
          <td>Yes</td>
          <td>0.5</td>
      </tr>
      <tr>
          <td>$r_3$</td>
          <td>No</td>
          <td>0</td>
      </tr>
  </tbody>
</table>
</li>
</ol>
<blockquote>
<ul>
<li>${ r&rsquo; : p = \text{&ldquo;green&rdquo;} \text{ is true of } r&rsquo; } = { r_1, r_2 }$</li>
<li>$|{ \dots }| = 2$</li>
</ul>
<h4 id="compute-probabilities-1">Compute Probabilities:<a hidden class="anchor" aria-hidden="true" href="#compute-probabilities-1">#</a></h4>
<ul>
<li>$P_{\text{literal}}(r_1 \mid \text{&ldquo;green&rdquo;}) = \frac{1}{2} = 0.5$</li>
<li>$P_{\text{literal}}(r_2 \mid \text{&ldquo;green&rdquo;}) = \frac{1}{2} = 0.5$</li>
<li>$P_{\text{literal}}(r_3 \mid \text{&ldquo;green&rdquo;}) = 0$</li>
</ul>
</blockquote>
<h4 id="example-2-listener-hears-square">Example 2: Listener Hears “square”<a hidden class="anchor" aria-hidden="true" href="#example-2-listener-hears-square">#</a></h4>
<ol>
<li>
<p>Determine which objects are compatible with the property &ldquo;square&rdquo;:<br>
→ Only $r_1$.</p>
</li>
<li>
<p>Assign Probabilities:</p>
<table>
  <thead>
      <tr>
          <th>Referent</th>
          <th>Compatible with &ldquo;square&rdquo;?</th>
          <th>$P_{\text{literal}}(r \mid p = \text{&ldquo;square&rdquo;})$</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>$r_1$</td>
          <td>Yes</td>
          <td>$1.0$</td>
      </tr>
      <tr>
          <td>$r_2$</td>
          <td>No</td>
          <td>$0$</td>
      </tr>
      <tr>
          <td>$r_3$</td>
          <td>No</td>
          <td>$0$</td>
      </tr>
  </tbody>
</table>
</li>
</ol>
<blockquote>
<ul>
<li>${ r&rsquo; : p = \text{&ldquo;square&rdquo;} \text{ is true of } r&rsquo; } = { r_1 }$</li>
<li>$ |{ \dots }| = 1 $</li>
</ul>
<h4 id="compute-probabilities-2">Compute Probabilities:<a hidden class="anchor" aria-hidden="true" href="#compute-probabilities-2">#</a></h4>
<ul>
<li>$P_{\text{literal}}(r_1 \mid \text{&ldquo;square&rdquo;}) = \frac{1}{1} = 1.0$</li>
<li>$P_{\text{literal}}(r_2 \mid \text{&ldquo;square&rdquo;}) = 0$</li>
<li>$P_{\text{literal}}(r_3 \mid \text{&ldquo;square&rdquo;}) = 0$</li>
</ul>
</blockquote>
<h4 id="example-3-listener-hears-blue">Example 3: Listener Hears “blue”<a hidden class="anchor" aria-hidden="true" href="#example-3-listener-hears-blue">#</a></h4>
<ol>
<li>
<p>Determine which objects are compatible with the property &ldquo;square&rdquo;:<br>
→ Only $r_1$.</p>
</li>
<li>
<p>Assign Probabilities:</p>
<table>
  <thead>
      <tr>
          <th>Referent</th>
          <th>Compatible with &ldquo;square&rdquo;?</th>
          <th>$P_{\text{literal}}(r \mid p = \text{&ldquo;square&rdquo;})$</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>$r_1$</td>
          <td>No</td>
          <td>$0.0$</td>
      </tr>
      <tr>
          <td>$r_2$</td>
          <td>No</td>
          <td>$0$</td>
      </tr>
      <tr>
          <td>$r_3$</td>
          <td>Yes</td>
          <td>$1.0$</td>
      </tr>
  </tbody>
</table>
</li>
</ol>
<blockquote>
<ul>
<li>${ r&rsquo; : p = \text{&ldquo;blue&rdquo;} \text{ is true of } r&rsquo; } = { r_3 }$</li>
<li>$ |{ \dots }| = 1 $</li>
</ul>
<h4 id="compute-probabilities-3">Compute Probabilities:<a hidden class="anchor" aria-hidden="true" href="#compute-probabilities-3">#</a></h4>
<ul>
<li>$P_{\text{literal}}(r_1 \mid \text{&ldquo;square&rdquo;}) = 0$</li>
<li>$P_{\text{literal}}(r_2 \mid \text{&ldquo;square&rdquo;}) = 0$</li>
<li>$P_{\text{literal}}(r_3 \mid \text{&ldquo;square&rdquo;}) = \frac{1}{1} = 1.0$</li>
</ul>
</blockquote>
<h3 id="55-pragmatic-speaker">5.5 Pragmatic Speaker<a hidden class="anchor" aria-hidden="true" href="#55-pragmatic-speaker">#</a></h3>
<p>$$
P_{prod}(p \mid r; \lambda, f) =
\frac{\exp\left( \lambda \cdot EU_{speaker}(r, p; f) \right)}{\displaystyle \sum_{p&rsquo;} \exp\left( \lambda \cdot EU_{speaker}(r, p&rsquo;; f) \right)}
$$</p>
<p>where $EU_{speaker}(r, p; f)$ is <strong>Utility Function</strong>:</p>
<p>$$
EU_{speaker}(r, p; f) = P_{literal}(r \mid p) + f(p)
$$</p>
<ul>
<li>$P_{literal}(r \mid p)$: How likely is it that a literal listener will pick referent $r$ after hearing $p$?</li>
<li>$f(p)$: Cost or bias term, penalizing utterances that are long, complex, or dispreferred.</li>
</ul>
<h4 id="explanation-of-components-1"><strong>Explanation of Components</strong><a hidden class="anchor" aria-hidden="true" href="#explanation-of-components-1">#</a></h4>
<table>
  <thead>
      <tr>
          <th>Symbol</th>
          <th>Explanation</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>$p$</td>
          <td>Property (utterance).</td>
      </tr>
      <tr>
          <td>$r$</td>
          <td>Referent (target object).</td>
      </tr>
      <tr>
          <td>$P_{prod} (p \mid r; \lambda, f)$</td>
          <td>Probability of Pragmatic Speaker choosing a property/utterance</td>
      </tr>
      <tr>
          <td>$\lambda$</td>
          <td>Rationality parameter (speaker’s sensitivity to utility differences).</td>
      </tr>
      <tr>
          <td>$f(p)$</td>
          <td>Cost or bias associated with utterance $p$.</td>
      </tr>
      <tr>
          <td>$ EU_{speaker}$</td>
          <td>Expected utility of utterance $p$ for referent $r$.</td>
      </tr>
  </tbody>
</table>
<p><strong><em>Combine the two</em></strong></p>
<p>$$ P_{prod}(p \mid r; \lambda, f) =
\frac{\exp\left( \lambda \cdot EU_{speaker}(r, p; f) \right)}{\displaystyle \sum_{p&rsquo;} \exp\left( \lambda \cdot EU_{speaker}(r, p&rsquo;; f) \right)} = \frac{\exp\left( \lambda \cdot (P_{literal}(r \mid p) + f(p)) \right)}{\displaystyle \sum_{p&rsquo;} \exp\left( \lambda \cdot (P_{literal}(r \mid p&rsquo;) + f(p&rsquo;)) \right)}
$$</p>
<h4 id="worked-example"><strong>Worked Example</strong><a hidden class="anchor" aria-hidden="true" href="#worked-example">#</a></h4>
<p>Scenario:</p>
<table>
  <thead>
      <tr>
          <th>Object</th>
          <th>Color</th>
          <th>Shape</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>$r_1$</td>
          <td>Green</td>
          <td>Square</td>
      </tr>
      <tr>
          <td>$r_2$</td>
          <td>Green</td>
          <td>Circle</td>
      </tr>
      <tr>
          <td>$r_3$</td>
          <td>Blue</td>
          <td>Circle</td>
      </tr>
  </tbody>
</table>
<ul>
<li>Target referent $r = r_1$ (Green Square).</li>
<li>Utterance/Property space: &ldquo;green&rdquo;, &ldquo;square&rdquo;. (<strong>Note that we limit the utterance choices to be of only &ldquo;green&rdquo; and &ldquo;square&rdquo;</strong> which are literally true of &ldquo;Green Square&rdquo;)</li>
</ul>
<blockquote>
<p>Note that the set of utterances to choose from matters in final Speaker&rsquo;s probability in choosing which utterance to use</p>
<ul>
<li>$u_1 \in \{ &ldquo;green&rdquo;, &ldquo;square&rdquo; \}$</li>
<li>$u_2 \in \{ \text{&ldquo;green&rdquo;}, \text{&ldquo;square&rdquo;}, \text{&ldquo;circle&rdquo;}, \text{&ldquo;blue&rdquo;} \}$</li>
</ul>
<h4 id="why-the-two-u-sets">why the two $u$ sets?<a hidden class="anchor" aria-hidden="true" href="#why-the-two-u-sets">#</a></h4>
<p>They lead to different Speaker&rsquo;s probabilities in choosing utterances to refer to a particular referent.
<strong>in the $u_2$ option, those semantically incompatible/literally false utterances/properties were also assigned probabilities</strong>.</p>
<h4 id="should-false-utterances-be-included">Should False Utterances Be Included?<a hidden class="anchor" aria-hidden="true" href="#should-false-utterances-be-included">#</a></h4>
<h4 id="option-1-full-utterance-set-even-non-true-ones">Option 1: Full Utterance Set (Even Non-True Ones)<a hidden class="anchor" aria-hidden="true" href="#option-1-full-utterance-set-even-non-true-ones">#</a></h4>
<p>Assumption:<br>
Speakers can, and sometimes do, use suboptimal or false utterances.</p>
<h4 id="model-characteristics">Model Characteristics:<a hidden class="anchor" aria-hidden="true" href="#model-characteristics">#</a></h4>
<ul>
<li>All utterances in the property space are <strong>included</strong>, regardless of literal truth.</li>
<li>Even non-true properties like <code>&quot;blue&quot;</code> (for a green object) receive <strong>non-zero probability</strong>, though down-weighted.</li>
<li>Matches the <strong>default RSA formulation</strong> as used in:
<ul>
<li><em>Franke &amp; Jäger (2016)</em></li>
<li><em>Goodman &amp; Frank (2016)</em></li>
</ul>
</li>
</ul>
<h4 id="when-to-use">When to Use:<a hidden class="anchor" aria-hidden="true" href="#when-to-use">#</a></h4>
<ul>
<li>You want to model <strong>noisy, probabilistic human behavior</strong>.</li>
<li>You&rsquo;re studying <strong>psycholinguistic behavior</strong>, overinformativeness, or slips.</li>
<li>You&rsquo;re interested in <strong>graded inference</strong> and <strong>soft competition</strong>.</li>
</ul>
<hr>
<h4 id="option-2-restricted-utterance-set-only-true-properties">Option 2: Restricted Utterance Set (Only True Properties)<a hidden class="anchor" aria-hidden="true" href="#option-2-restricted-utterance-set-only-true-properties">#</a></h4>
<h4 id="assumption">Assumption:<a hidden class="anchor" aria-hidden="true" href="#assumption">#</a></h4>
<p>Speakers are always semantically competent and never use false utterances.</p>
<h4 id="model-characteristics-1">Model Characteristics:<a hidden class="anchor" aria-hidden="true" href="#model-characteristics-1">#</a></h4>
<ul>
<li>The utterance set is <strong>filtered</strong> to include only properties that are literally true of the referent.</li>
<li>Softmax normalization is applied <strong>only over true utterances</strong>.</li>
<li>Produces <strong>sharper speaker preferences</strong> and downstream listener inference.</li>
</ul>
<h4 id="when-to-use-1">When to Use:<a hidden class="anchor" aria-hidden="true" href="#when-to-use-1">#</a></h4>
<ul>
<li>You&rsquo;re modeling <strong>idealized agents</strong> in formal semantics or decision theory.</li>
<li>Your research assumes <strong>strict informativeness</strong>.</li>
<li>You&rsquo;re simulating <strong>maximally rational communication</strong>.</li>
</ul>
</blockquote>
<p><strong><em>Speaker production probabilities calculation</em></strong><br>
<em>Step 1: Assume:</em></p>
<ul>
<li>$\lambda = 1$ (moderate rationality).</li>
<li>$f(p) = 0$ (no production cost).</li>
</ul>
<p><em>Step 2: Compute $P_{literal}(r \mid p)$</em></p>
<ul>
<li>
<p>Literal Listener for $&ldquo;green&rdquo;$:</p>
<ul>
<li>Compatible referents: $r_1$, $r_2$.</li>
<li>$P_{\text{literal}}(r_1 \mid \text{&ldquo;green&rdquo;}) = \frac{1}{2} = 0.5$</li>
</ul>
</li>
<li>
<p>Literal Listener for $&ldquo;square&rdquo;$:</p>
<ul>
<li>Only $r_1$ is a square.</li>
<li>$P_{literal}(r_1 \mid {&ldquo;square&rdquo;}) = 1.0$</li>
</ul>
</li>
</ul>
<p><em>Step 3: Compute Utility for Each Utterance</em></p>
<p>$EU_{speaker}(r_1, &ldquo;green&rdquo;; f) = P_{literal}(r_1 \mid &ldquo;green&rdquo;) + f(&ldquo;green&rdquo;) = 0.5 + 0 = 0.5$<br>
$EU_{speaker}(r_1, &ldquo;square&rdquo;; f) = P_{literal}(r_1 \mid &ldquo;square&rdquo;) + f(&ldquo;square&rdquo;) = 1.0 + 0 = 1.0$</p>
<p><em>Step 4: Compute Unnormalized Scores</em> Using $\exp\left(\lambda \cdot EU_{speaker}(r, p; f)\right) $:</p>
<ul>
<li>$ \exp\left(\lambda \cdot  EU_{speaker}(r_1, &ldquo;green&rdquo;; f) \right) = \exp(1 \cdot 0.5) = \exp(0.5) \approx 1.649$</li>
<li>$\exp\left(\lambda \cdot EU_{speaker}(r_1, &ldquo;square&rdquo;; f) \right) = \exp(1 \cdot 1.0) = \exp(1) \approx 2.718$</li>
</ul>
<blockquote>
<p><strong>What Does $\exp(0.5)$ Mean?</strong></p>
<ul>
<li>$\exp(x)$ is the <strong>exponential function</strong>, defined as:</li>
</ul>
<p>$ \exp(x) = e^x $</p>
<ul>
<li>Where <strong>$e \approx 2.71828$</strong> is $Euler’s$ number, a fundamental constant in mathematics.</li>
</ul>
<p><strong>Why Is This Important in RSA?</strong></p>
<ul>
<li>The exponential function <strong>transforms utility values into positive scores</strong>.</li>
<li>It ensures that higher-utility utterances lead to higher scores in the <strong>softmax calculation</strong> for final probabilities.</li>
<li>Without exponentiation, negative utilities could produce invalid (negative) probabilities.</li>
</ul>
<h4 id="quick-reference-table"><strong>Quick Reference Table</strong><a hidden class="anchor" aria-hidden="true" href="#quick-reference-table">#</a></h4>
<table>
  <thead>
      <tr>
          <th>Utility $EU(p, r)$</th>
          <th>$\exp(EU)$</th>
          <th>Interpretation</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>0</td>
          <td>1.0</td>
          <td>Baseline utility.</td>
      </tr>
      <tr>
          <td>0.5</td>
          <td>1.649</td>
          <td>Moderately high utility.</td>
      </tr>
      <tr>
          <td>1.0</td>
          <td>2.718</td>
          <td>High utility.</td>
      </tr>
      <tr>
          <td>-1.386</td>
          <td>0.25</td>
          <td>Low utility (as in $\log(0.25)$).</td>
      </tr>
  </tbody>
</table>
</blockquote>
<p><em>Step 5: Normalize to Get Final Probabilities</em></p>
<p>$ Total = \exp\left( \lambda \cdot EU_{speaker}(r_1, green&rsquo;; f) \right) + \exp\left( \lambda \cdot EU_{speaker}(r_1, square&rsquo;; f) \right) =1.649 + 2.718 = 4.367 $</p>
<ul>
<li>$P_{prod}({&ldquo;green&rdquo;} \mid r_1) = \frac{\exp\left( \lambda \cdot EU_{speaker}(r_1, &ldquo;green&rdquo;; f) \right)}{\sum_{p&rsquo;} \exp\left( \lambda \cdot EU_{speaker}(r, p&rsquo;; f) \right)} =
\frac{1.649}{4.367} \approx 0.378$</li>
<li>$P_{\text{prod}}(\text{&ldquo;square&rdquo;} \mid r_1) = \frac{\exp\left( \lambda \cdot EU_{speaker}(r_1, &ldquo;square&rdquo;; f) \right)}{\sum_{p&rsquo;} \exp\left( \lambda \cdot EU_{speaker}(r, p&rsquo;; f) \right)} = \frac{2.718}{4.367} \approx 0.622$</li>
</ul>
<h4 id="final-interpretation-4">Final Interpretation<a hidden class="anchor" aria-hidden="true" href="#final-interpretation-4">#</a></h4>
<table>
  <thead>
      <tr>
          <th>Utterance</th>
          <th>$P_{\text{prod}}(p \mid r_1)$</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>&ldquo;green&rdquo;</td>
          <td>0.378 (38%)</td>
      </tr>
      <tr>
          <td>&ldquo;square&rdquo;</td>
          <td>0.622 (62%)</td>
      </tr>
  </tbody>
</table>
<ul>
<li>These are the Pragmatic Speaker&rsquo;s probabilities in choosing &ldquo;green&rdquo; or &ldquo;square&rdquo; to refer to $r_1$  (Green Square)</li>
<li>The speaker prefers &ldquo;square&rdquo; but still sometimes chooses &ldquo;green&rdquo;.</li>
<li>This reflects probabilistic, graded behavior rather than deterministic selection.</li>
</ul>
<h4 id="key-insights"><strong>Key Insights</strong><a hidden class="anchor" aria-hidden="true" href="#key-insights">#</a></h4>
<ul>
<li>
<p><strong>Higher Utility → Higher Probability</strong><br>
But not necessarily 100%, depending on $\lambda$.</p>
</li>
<li>
<p><strong>Effect of $\lambda$</strong>:</p>
<ul>
<li>If $\lambda = 0$, the speaker would choose &ldquo;green&rdquo; and &ldquo;square&rdquo; randomly.</li>
<li>If $\lambda \to \infty$, the speaker would always choose &ldquo;square&rdquo;.</li>
</ul>
</li>
<li>
<p><strong>Effect of Cost $f(p)$</strong>:</p>
<ul>
<li>If &ldquo;square&rdquo; had a higher cost, the speaker might prefer &ldquo;green&rdquo; despite its lower informativeness.</li>
</ul>
</li>
</ul>
<hr>
<h3 id="56-pragmatic-listener">5.6 Pragmatic Listener<a hidden class="anchor" aria-hidden="true" href="#56-pragmatic-listener">#</a></h3>
<p>In the RSA model, the <strong>pragmatic listener</strong> ($L_1$) updates beliefs about the speaker’s intended referent based on the utterance they receive. This is done using <strong>Bayes&rsquo; Rule</strong> and the listener’s model of the speaker.</p>
<p>$$
P_{comp}(\text{choose } r \mid \text{receive } p;\ \lambda, f) = \frac{P(r) \cdot P_{prod}(p \mid r;\ \lambda, f)}{\displaystyle \sum_{r&rsquo;} P(r&rsquo;) \cdot P_{prod}(p \mid r&rsquo;;\ \lambda, f)}
$$</p>
<h4 id="explanation-of-components-2">Explanation of Components<a hidden class="anchor" aria-hidden="true" href="#explanation-of-components-2">#</a></h4>
<table>
  <thead>
      <tr>
          <th>Symbol</th>
          <th>Meaning</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>$r$</td>
          <td>A possible referent (object)</td>
      </tr>
      <tr>
          <td>$p$</td>
          <td>The utterance (property) received from the speaker</td>
      </tr>
      <tr>
          <td>$P(r)$</td>
          <td>Prior probability of referent $r$</td>
      </tr>
      <tr>
          <td>$P_{prod}(p \mid r;\ \lambda, f)$</td>
          <td>Probability that a speaker with parameters $(\lambda, f)$ would produce $p$ when referring to $r$</td>
      </tr>
      <tr>
          <td>$\lambda$</td>
          <td>Rationality parameter (how optimally the speaker chooses)</td>
      </tr>
      <tr>
          <td>$f(p)$</td>
          <td>Cost or bias associated with producing utterance $p$</td>
      </tr>
      <tr>
          <td>$r'$</td>
          <td>Variable over all referents used to normalize the distribution</td>
      </tr>
  </tbody>
</table>
<h4 id="intuition">Intuition<a hidden class="anchor" aria-hidden="true" href="#intuition">#</a></h4>
<blockquote>
<p>The listener <strong>reasons backward</strong>:<br>
“If the speaker chose to say $p$, which referent $r$ would make that utterance most likely—assuming they were optimizing utility using $\lambda$ and $f$?”</p>
</blockquote>
<p>This is a form of <strong>Bayesian social reasoning</strong>:</p>
<ul>
<li>The listener assumes the speaker is rational (to some degree),</li>
<li>and uses this model to infer likely referents.</li>
</ul>
<h4 id="example">Example<a hidden class="anchor" aria-hidden="true" href="#example">#</a></h4>
<p><em><strong>Referents</strong></em></p>
<table>
  <thead>
      <tr>
          <th>Code</th>
          <th>Description</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>$r_1$</td>
          <td>Green Square</td>
      </tr>
      <tr>
          <td>$r_2$</td>
          <td>Green Circle</td>
      </tr>
      <tr>
          <td>$r_3$</td>
          <td>Blue Circle</td>
      </tr>
  </tbody>
</table>
<p>Possible utterances (utterance space): &ldquo;green&rdquo;, &ldquo;square&rdquo;, &ldquo;circle&rdquo;, &ldquo;blue&rdquo;</p>
<p><em>Step 1: Assumed Prior</em></p>
<p>Uniform prior:  $ P(r_1) = P(r_2) = P(r_3) = \frac{1}{3} $</p>
<p><em>Step 2: calculate Pragmatic Speaker&rsquo;s Probability of choosing &ldquo;green&rdquo; for each of three referent</em>
(using λ = 1, no cost bias $f(p) = 0$):</p>
<blockquote>
<p><strong>1. probability of intending $r_1$ (green square)</strong> for each option in the utterance/property space</p>
<h4 id="step-1-literal-listener-probabilities">Step 1: Literal Listener Probabilities<a hidden class="anchor" aria-hidden="true" href="#step-1-literal-listener-probabilities">#</a></h4>
<ul>
<li>$P_{literal}(r_1 \mid \text{&ldquo;green&rdquo;}) = \frac{1}{2} = 0.5$</li>
<li>$P_{literal}(r_1 \mid \text{&ldquo;square&rdquo;}) = 1.0$</li>
<li>$P_{literal}(r_1 \mid \text{&ldquo;circle&rdquo;}) = 0$</li>
<li>$P_{literal}(r_1 \mid \text{&ldquo;blue&rdquo;}) = 0$</li>
</ul>
<h4 id="step-2-pragmatic-speaker-probabilities">Step 2: Pragmatic Speaker Probabilities<a hidden class="anchor" aria-hidden="true" href="#step-2-pragmatic-speaker-probabilities">#</a></h4>
<p>The formula of Pragmatic Speaker is:
$$ P_{prod}(p \mid r; \lambda, f) =  \frac{\exp\left( \lambda \cdot EU_{speaker}(r, p; f) \right)}{\sum_{p&rsquo;} \exp\left( \lambda \cdot EU_{speaker}(r, p&rsquo;; f) \right)} = \frac{\exp\left( \lambda \cdot (P_{literal}(r \mid p) + f(p)) \right)}{\sum_{p&rsquo;} \exp\left( \lambda \cdot (P_{literal}(r \mid p&rsquo;) + f(p&rsquo;)) \right)}
$$</p>
<h4 id="step-21-compute-eu-values">step 2.1: Compute $EU$ Values<a hidden class="anchor" aria-hidden="true" href="#step-21-compute-eu-values">#</a></h4>
<ul>
<li>$EU(r_1, \text{&ldquo;green&rdquo;; f}) = P_{literal}(r_1 \mid &ldquo;green&rdquo;) + f(&ldquo;green&rdquo;) = 0.5 + 0 = 0.5$</li>
<li>$EU(r_1, \text{&ldquo;square&rdquo;}; f) = P_{literal}(r_1 \mid &ldquo;green&rdquo;) + f(p) = 1.0 + 0 = 1.0$</li>
<li>$EU(r_1, \text{&ldquo;circle&rdquo;}; f) = P_{literal}(r_1 \mid &ldquo;green&rdquo;) + f(p) = 0 + 0 = 0$</li>
<li>$EU(r_1, \text{&ldquo;blue&rdquo;}; f) = P_{literal}(r_1 \mid &ldquo;blue&rdquo;) + f(p) = 0 + 0 = 0$</li>
</ul>
<h4 id="step-22-exponentiate-and-normalize">Step 2.2: Exponentiate and Normalize<a hidden class="anchor" aria-hidden="true" href="#step-22-exponentiate-and-normalize">#</a></h4>
<p>Exponentiate:</p>
<ul>
<li>$\exp\left( \lambda \cdot EU_{speaker}(r_1, &ldquo;green&rdquo;; f) \right) = \exp(1 \cdot 0.5) = \exp(0.5)\approx 1.649$</li>
<li>$\exp\left( \lambda \cdot EU_{speaker}(r_1, &ldquo;square&rdquo;; f) \right) = \exp(1 \cdot 1.0) = \exp(1)\approx 2.718$</li>
<li>$\exp\left( \lambda \cdot EU_{speaker}(r_1, &ldquo;circle&rdquo;; f) \right) = \exp(1 \cdot 0) = \exp(0) = 1.0$</li>
<li>$\exp\left( \lambda \cdot EU_{speaker}(r_1, &ldquo;blue&rdquo;; f) \right) = \exp(1 \cdot 0) = \exp(0) = 1.0$</li>
</ul>
<p>Total sum:<br>
$$
1.649 + 2.718 + 1.0 + 1.0 = 6.367
$$</p>
<p>Final probabilities:</p>
<ul>
<li>$P_{prod}(\text{&ldquo;green&rdquo;} \mid r_1) = \frac{1.649}{6.367} \approx 0.2589$</li>
<li>$P_{prod}(\text{&ldquo;square&rdquo;} \mid r_1) = \frac{2.718}{6.367} \approx 0.4269$</li>
<li>$P_{prod}(\text{&ldquo;circle&rdquo;} \mid r_1) = \frac{1.0}{6.367} \approx 0.1571$</li>
<li>$P_{prod}(\text{&ldquo;blue&rdquo;} \mid r_1) = \frac{1.0}{6.367} \approx 0.1571$</li>
</ul>
<hr>
<p><strong>2. probability of intending $r_2$ (green circle)</strong> for each option in the utterance/property space</p>
<h4 id="literal-listener-probabilities">Literal Listener Probabilities<a hidden class="anchor" aria-hidden="true" href="#literal-listener-probabilities">#</a></h4>
<ul>
<li>$P_{literal}(r_2 \mid &ldquo;green&rdquo;) = \frac{1}{2} = 0.5$</li>
<li>$P_{literal}(r_2 \mid &ldquo;square&rdquo;) = 0$</li>
<li>$P_{literal}(r_2 \mid &ldquo;circle&rdquo;) = \frac{1}{2} = 0.5$</li>
<li>$P_{literal}(r_2 \mid &ldquo;blue&rdquo;) = 0$</li>
</ul>
<h4 id="step-2-pragmatic-speaker-probabilities-1">Step 2: Pragmatic Speaker Probabilities<a hidden class="anchor" aria-hidden="true" href="#step-2-pragmatic-speaker-probabilities-1">#</a></h4>
<h4 id="step-21-compute-eu-values-1">step 2.1: Compute $EU$ Values<a hidden class="anchor" aria-hidden="true" href="#step-21-compute-eu-values-1">#</a></h4>
<ul>
<li>$EU(r_2, \text{&ldquo;green&rdquo;; f}) = P_{literal}(r_1 \mid &ldquo;green&rdquo;) + f(&ldquo;green&rdquo;) = 0.5 + 0 = 0.5$</li>
<li>$EU(r_2, \text{&ldquo;square&rdquo;}; f) = P_{literal}(r_1 \mid &ldquo;green&rdquo;) + f(p) = 0 + 0 = 0$</li>
<li>$EU(r_2, \text{&ldquo;circle&rdquo;}; f) = P_{literal}(r_1 \mid &ldquo;green&rdquo;) + f(p) = 0.5 + 0 = 0.5 $</li>
<li>$EU(r_2, \text{&ldquo;blue&rdquo;}; f) = P_{literal}(r_1 \mid &ldquo;blue&rdquo;) + f(p) = 0 + 0 = 0 $</li>
</ul>
<h4 id="step-22-exponentiate-and-normalize-1">Step 2.2: Exponentiate and Normalize<a hidden class="anchor" aria-hidden="true" href="#step-22-exponentiate-and-normalize-1">#</a></h4>
<p>Exponentiate:</p>
<ul>
<li>$\exp\left( \lambda \cdot EU_{speaker}(r_2, &ldquo;green&rdquo;; f) \right) = \exp(1 \cdot 0.5) = \exp(0.5)\approx 1.649$</li>
<li>$\exp\left( \lambda \cdot EU_{speaker}(r_2, &ldquo;square&rdquo;; f) \right) = \exp(1 \cdot 0) = \exp(0) = 1$</li>
<li>$\exp\left( \lambda \cdot EU_{speaker}(r_2, &ldquo;circle&rdquo;; f) \right) = \exp(1 \cdot 0.5) = \exp(0.5) \approx 1.649$</li>
<li>$\exp\left( \lambda \cdot EU_{speaker}(r_2, &ldquo;blue&rdquo;; f) \right) = \exp(1 \cdot 0) = \exp(0) = 1$</li>
</ul>
<p>Total:<br>
$$
1.649 + 1 + 1.649 + 1 = 5.298
$$</p>
<p>Final probabilities:</p>
<ul>
<li>$P_{prod}(\text{&ldquo;green&rdquo;} \mid r_2) = \frac{1.649}{4.298} \approx 0.3112$</li>
<li>$P_{prod}(\text{&ldquo;square&rdquo;} \mid r_2) = \frac{1}{4.298} \approx 0.1888$</li>
<li>$P_{prod}(\text{&ldquo;circle&rdquo;} \mid r_2) = \frac{1.649}{4.298} \approx 0.3112$</li>
<li>$P_{prod}(\text{&ldquo;blue&rdquo;} \mid r_2) = \frac{1}{4.298} \approx 0.1888$</li>
</ul>
<hr>
<p><strong>3. probability of intending $r_3$ (blue circle)</strong> for each option in the utterance/property space</p>
<h4 id="literal-listener-probabilities-1">Literal Listener Probabilities<a hidden class="anchor" aria-hidden="true" href="#literal-listener-probabilities-1">#</a></h4>
<ul>
<li>$P_{literal}(r_2 \mid &ldquo;green&rdquo;) = 0$</li>
<li>$P_{literal}(r_2 \mid &ldquo;square&rdquo;) = 0$</li>
<li>$P_{literal}(r_2 \mid &ldquo;circle&rdquo;) = \frac{1}{2} = 0.5$</li>
<li>$P_{literal}(r_2 \mid &ldquo;blue&rdquo;) = \frac{1}{1} = 1$</li>
</ul>
<h4 id="step-2-pragmatic-speaker-probabilities-2">Step 2: Pragmatic Speaker Probabilities<a hidden class="anchor" aria-hidden="true" href="#step-2-pragmatic-speaker-probabilities-2">#</a></h4>
<h4 id="step-21-compute-eu-values-2">step 2.1: Compute $EU$ Values<a hidden class="anchor" aria-hidden="true" href="#step-21-compute-eu-values-2">#</a></h4>
<ul>
<li>$EU(r_3, \text{&ldquo;green&rdquo;; f}) = P_{literal}(r_3 \mid &ldquo;green&rdquo;) + f(&ldquo;green&rdquo;) = 0 + 0 = 0$</li>
<li>$EU(r_3, \text{&ldquo;square&rdquo;}; f) = P_{literal}(r_3 \mid &ldquo;green&rdquo;) + f(p) = 0 + 0 = 0$</li>
<li>$EU(r_3, \text{&ldquo;circle&rdquo;}; f) = P_{literal}(r_3 \mid &ldquo;green&rdquo;) + f(p) = 0.5 + 0 = 0.5 $</li>
<li>$EU(r_3, \text{&ldquo;blue&rdquo;}; f) = P_{literal}(r_3 \mid &ldquo;blue&rdquo;) + f(p) = 1 + 0 = 1 $</li>
</ul>
<h4 id="step-22-exponentiate-and-normalize-2">Step 2.2: Exponentiate and Normalize<a hidden class="anchor" aria-hidden="true" href="#step-22-exponentiate-and-normalize-2">#</a></h4>
<p>Exponentiate:</p>
<ul>
<li>$\exp\left( \lambda \cdot EU_{speaker}(r_3, &ldquo;green&rdquo;; f) \right) = \exp(1 \cdot 0) = \exp(0) = 1$</li>
<li>$\exp\left( \lambda \cdot EU_{speaker}(r_3, &ldquo;square&rdquo;; f) \right) = \exp(1 \cdot 0) = \exp(0) = 1$</li>
<li>$\exp\left( \lambda \cdot EU_{speaker}(r_3, &ldquo;circle&rdquo;; f) \right) = \exp(1 \cdot 0.5) = \exp(0.5) \approx 1.649$</li>
<li>$\exp\left( \lambda \cdot EU_{speaker}(r_3, &ldquo;blue&rdquo;; f) \right) = \exp(1 \cdot 1) = \exp(1) \approx 2.718$</li>
</ul>
<p>Total:  $ 1 + 1 + 1.649 + 2.718 = 6.367 $</p>
<p>Final probabilities:</p>
<ul>
<li>$P_{prod}(\text{&ldquo;green&rdquo;} \mid r_3) = \frac{1}{6.367} \approx 0.1571$</li>
<li>$P_{prod}(\text{&ldquo;square&rdquo;} \mid r_3) = \frac{1}{6.367} \approx 0.1571$</li>
<li>$P_{prod}(\text{&ldquo;circle&rdquo;} \mid r_3) = \frac{1.64}{6.367} \approx 0.2589$</li>
<li>$P_{prod}(\text{&ldquo;blue&rdquo;} \mid r_3) = \frac{2.718}{6.367} \approx 0.4269$</li>
</ul>
</blockquote>
<hr>
<h3 id="extra">Extra<a hidden class="anchor" aria-hidden="true" href="#extra">#</a></h3>
<h3 id="extra-1-lambda-lambda">Extra #1 Lambda $\lambda$<a hidden class="anchor" aria-hidden="true" href="#extra-1-lambda-lambda">#</a></h3>
<p>In the Rational Speech Act (RSA) model, <strong>λ (lambda)</strong> appears in the <strong>Pragmatic Speaker equation</strong>, where it controls how strongly the speaker favors higher-utility utterances.</p>
<h4 id="core-intuition">Core Intuition:<a hidden class="anchor" aria-hidden="true" href="#core-intuition">#</a></h4>
<blockquote>
<p>λ determines how <strong>deterministic or probabilistic</strong> the speaker’s utterance choices are.</p>
</blockquote>
<h4 id="where-does-λ-appear">Where Does λ Appear?<a hidden class="anchor" aria-hidden="true" href="#where-does-λ-appear">#</a></h4>
<p>In <strong>Franke &amp; Jäger (2016)</strong>, the Pragmatic Speaker is modeled as:</p>
<p>$$
P_{prod}(p \mid r; \lambda, f) = \frac{\exp\left( \lambda \cdot EU(r, p; f) \right)}{\sum_{p&rsquo;} \exp\left( \lambda \cdot EU(r, p&rsquo;; f) \right)}
$$</p>
<ul>
<li>$p$: utterance (property)</li>
<li>$r$: intended referent</li>
<li>$f(p)$: cost or bias of utterance</li>
<li>$EU(r, p; f)$: utility of utterance $p$ for referent $r$</li>
<li><strong>λ</strong>: rationality parameter</li>
</ul>
<h4 id="what-does-λ-do">What Does λ Do?<a hidden class="anchor" aria-hidden="true" href="#what-does-λ-do">#</a></h4>
<ul>
<li>λ <strong>scales</strong> the utility before exponentiation.</li>
<li>It determines <strong>how much more likely</strong> the speaker is to choose high-utility utterances over others.</li>
</ul>
<h4 id="effects-of-different-λ-values">Effects of Different λ Values<a hidden class="anchor" aria-hidden="true" href="#effects-of-different-λ-values">#</a></h4>
<table>
  <thead>
      <tr>
          <th>λ Value</th>
          <th>Speaker Behavior</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>0</td>
          <td>Completely random (uniform choice)</td>
      </tr>
      <tr>
          <td>~0.5</td>
          <td>Weak preference for better options</td>
      </tr>
      <tr>
          <td>1</td>
          <td>Moderate, probabilistic choice</td>
      </tr>
      <tr>
          <td>&gt;5</td>
          <td>Strong preference for best option</td>
      </tr>
      <tr>
          <td>→ ∞</td>
          <td>Always chooses highest-utility utterance</td>
      </tr>
  </tbody>
</table>
<h4 id="mathematical-background">Mathematical Background<a hidden class="anchor" aria-hidden="true" href="#mathematical-background">#</a></h4>
<h4 id="softmax-function">Softmax Function<a hidden class="anchor" aria-hidden="true" href="#softmax-function">#</a></h4>
<p>The softmax is a smooth version of the <strong>argmax</strong>:</p>
<p>$$
\text{softmax}_i(x) = \frac{\exp(\lambda x_i)}{\sum_j \exp(\lambda x_j)}
$$</p>
<ul>
<li>λ controls the <strong>sharpness</strong> of the preference.</li>
<li>High λ → output resembles a hard decision (argmax).</li>
<li>Low λ → output is closer to uniform probability.</li>
</ul>
<h4 id="connection-to-statistical-physics">Connection to Statistical Physics<a hidden class="anchor" aria-hidden="true" href="#connection-to-statistical-physics">#</a></h4>
<p>In the <strong>Boltzmann distribution</strong>:</p>
<p>$$
P_i = \frac{\exp(-E_i / kT)}{\sum_j \exp(-E_j / kT)}
$$</p>
<ul>
<li>$T$ is temperature.</li>
<li>RSA’s λ is analogous to <strong>inverse temperature</strong>:</li>
</ul>
<p>$$
\lambda = \frac{1}{T}
$$</p>
<ul>
<li>Low temperature (high λ) → more deterministic.</li>
<li>High temperature (low λ) → more randomness.</li>
</ul>
<h4 id="link-to-decision-theory">Link to Decision Theory<a hidden class="anchor" aria-hidden="true" href="#link-to-decision-theory">#</a></h4>
<ul>
<li>Softmax choice reflects <strong>bounded rationality</strong>.</li>
<li>Agents aren’t fully deterministic, but biased toward better options.</li>
<li>λ represents <strong>decision sharpness</strong> or <strong>confidence</strong>.</li>
</ul>
<h4 id="numerical-example">Numerical Example<a hidden class="anchor" aria-hidden="true" href="#numerical-example">#</a></h4>
<p>Suppose:</p>
<ul>
<li>$EU(\text{&ldquo;square&rdquo;}) = 1.0$</li>
<li>$EU(\text{&ldquo;green&rdquo;}) = 0.5$</li>
</ul>
<p>Then:</p>
<ul>
<li>
<p>With λ = 1:</p>
<p>$$
\exp(1 \cdot 1.0) = 2.718,\quad \exp(1 \cdot 0.5) = 1.649
$$</p>
</li>
<li>
<p>Normalize:</p>
<p>$$
\text{Total} = 2.718 + 1.649 = 4.367
$$</p>
<p>$$
P(\text{&ldquo;square&rdquo;}) = \frac{2.718}{4.367} \approx 0.622,\quad P(\text{&ldquo;green&rdquo;}) = \frac{1.649}{4.367} \approx 0.378
$$</p>
</li>
</ul>
<p>The speaker prefers &ldquo;square&rdquo; but still sometimes says &ldquo;green&rdquo;.</p>
<h4 id="summary-table">Summary Table<a hidden class="anchor" aria-hidden="true" href="#summary-table">#</a></h4>
<table>
  <thead>
      <tr>
          <th>Concept</th>
          <th>Interpretation</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>λ (lambda)</td>
          <td>Rationality or sensitivity to utility</td>
      </tr>
      <tr>
          <td>Low λ</td>
          <td>Speaker behaves more randomly</td>
      </tr>
      <tr>
          <td>High λ</td>
          <td>Speaker consistently chooses best utterance</td>
      </tr>
      <tr>
          <td>λ = 0</td>
          <td>Speaker chooses uniformly</td>
      </tr>
      <tr>
          <td>λ → ∞</td>
          <td>Speaker chooses deterministically</td>
      </tr>
      <tr>
          <td>Mathematical Function</td>
          <td>Appears inside exponential in softmax</td>
      </tr>
  </tbody>
</table>
<h4 id="final-takeaway">Final Takeaway<a hidden class="anchor" aria-hidden="true" href="#final-takeaway">#</a></h4>
<blockquote>
<p>λ gives the RSA model <strong>flexibility</strong> to represent real human speakers who are sometimes decisive and sometimes probabilistic in their choices. It controls the <strong>softness of rationality</strong> in utterance production.</p>
</blockquote>
<hr>
<h3 id="extra-2-softmax-function">Extra #2 Softmax Function<a hidden class="anchor" aria-hidden="true" href="#extra-2-softmax-function">#</a></h3>
<h4 id="why-is-the-softmax-function-used-in-the-pragmatic-speaker-formula">Why Is the Softmax Function Used in the Pragmatic Speaker Formula?<a hidden class="anchor" aria-hidden="true" href="#why-is-the-softmax-function-used-in-the-pragmatic-speaker-formula">#</a></h4>
<p>In the RSA model, the <strong>Pragmatic Speaker</strong> chooses among possible utterances to convey an intended referent.<br>
The model assumes the speaker is <strong>rational but probabilistic</strong>.</p>
<h4 id="the-formula-franke--jäger-2016">The Formula (Franke &amp; Jäger, 2016)<a hidden class="anchor" aria-hidden="true" href="#the-formula-franke--jäger-2016">#</a></h4>
<p>The speaker&rsquo;s production probability is defined as:</p>
<p>$$
P_{prod}(p \mid r; \lambda, f) = \frac{\exp\left( \lambda \cdot EU(r, p; f) \right)}{\sum_{p&rsquo;} \exp\left( \lambda \cdot EU(r, p&rsquo;; f) \right)}
$$</p>
<ul>
<li>$p$: property/utterance</li>
<li>$r$: intended referent</li>
<li>$\lambda$: rationality parameter</li>
<li>$f(p)$: utterance bias or cost</li>
<li>$EU(r, p; f)$: expected utility of utterance $p$ for referent $r$</li>
</ul>
<h4 id="what-is-the-softmax-function-doing-here">What Is the Softmax Function Doing Here?<a hidden class="anchor" aria-hidden="true" href="#what-is-the-softmax-function-doing-here">#</a></h4>
<p>The softmax function:</p>
<p>$$
\text{softmax}_i(x) = \frac{\exp(\lambda x_i)}{\sum_j \exp(\lambda x_j)}
$$</p>
<p>is used to <strong>turn utility scores into probabilities</strong>. This is crucial in RSA because:</p>
<h4 id="1-it-maps-utility-to-probability">1. It Maps Utility to Probability<a hidden class="anchor" aria-hidden="true" href="#1-it-maps-utility-to-probability">#</a></h4>
<ul>
<li>Higher utility → higher probability</li>
<li>But all utterances still have <strong>some chance</strong> of being chosen</li>
<li>This models <strong>graded speaker behavior</strong></li>
</ul>
<h4 id="2-it-reflects-real-human-behavior">2. It Reflects Real Human Behavior<a hidden class="anchor" aria-hidden="true" href="#2-it-reflects-real-human-behavior">#</a></h4>
<p>Humans don’t always choose the &ldquo;best&rdquo; utterance. They might:</p>
<ul>
<li>Be uncertain</li>
<li>Prefer shorter or easier words</li>
<li>Make probabilistic rather than deterministic decisions</li>
</ul>
<p>Softmax <strong>captures this variation</strong>.</p>
<h4 id="3-it-controls-rationality-via-λ">3. It Controls Rationality via λ<a hidden class="anchor" aria-hidden="true" href="#3-it-controls-rationality-via-λ">#</a></h4>
<table>
  <thead>
      <tr>
          <th>λ Value</th>
          <th>Speaker Behavior</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>λ = 0</td>
          <td>Completely random</td>
      </tr>
      <tr>
          <td>λ = 1</td>
          <td>Matches utility proportionality</td>
      </tr>
      <tr>
          <td>λ → ∞</td>
          <td>Always chooses best option</td>
      </tr>
  </tbody>
</table>
<ul>
<li>λ allows the model to simulate <strong>different levels of speaker precision</strong></li>
<li>This is sometimes called <strong>bounded rationality</strong></li>
</ul>
<h4 id="4-it-enables-listener-inference">4. It Enables Listener Inference<a hidden class="anchor" aria-hidden="true" href="#4-it-enables-listener-inference">#</a></h4>
<p>Listeners in RSA models <strong>reverse-engineer speaker choices</strong>.<br>
Softmax:</p>
<ul>
<li>Makes speaker behavior <strong>invertible</strong> using Bayes’ rule</li>
<li>Lets listeners reason: <em>“Why would the speaker have said that?”</em></li>
</ul>
<h4 id="5-its-a-standard-tool-in-decision-and-learning-models">5. It’s a Standard Tool in Decision and Learning Models<a hidden class="anchor" aria-hidden="true" href="#5-its-a-standard-tool-in-decision-and-learning-models">#</a></h4>
<ul>
<li>Used in machine learning (e.g., neural networks)</li>
<li>Used in economics (e.g., quantal response models)</li>
<li>Used in reinforcement learning (for action selection)</li>
</ul>
<p>Softmax in RSA makes the model mathematically <strong>standard, general, and interpretable</strong>.</p>
<h4 id="intuition-1">Intuition<a hidden class="anchor" aria-hidden="true" href="#intuition-1">#</a></h4>
<blockquote>
<p>Softmax lets the speaker be smart—but not rigid.<br>
Better utterances are more likely, but nothing is guaranteed.</p>
</blockquote>
<h4 id="summary-table-1">Summary Table<a hidden class="anchor" aria-hidden="true" href="#summary-table-1">#</a></h4>
<table>
  <thead>
      <tr>
          <th>Feature</th>
          <th>Why Softmax Helps in RSA</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>Maps utility → probability</td>
          <td>Valid probability distribution</td>
      </tr>
      <tr>
          <td>Captures human behavior</td>
          <td>Models graded, non-deterministic choices</td>
      </tr>
      <tr>
          <td>Flexible rationality</td>
          <td>λ controls how sharp or flat the distribution is</td>
      </tr>
      <tr>
          <td>Bayesian inference support</td>
          <td>Listener can reason backwards</td>
      </tr>
      <tr>
          <td>Standard modeling tool</td>
          <td>Widely used in cognitive science and AI</td>
      </tr>
  </tbody>
</table>
<h3 id="extra-3-lambda-softmax-visualizer">Extra #3 Lambda Softmax Visualizer<a hidden class="anchor" aria-hidden="true" href="#extra-3-lambda-softmax-visualizer">#</a></h3>
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Softmax Visualization</title>
  <script src="https://cdn.jsdelivr.net/npm/mathjs@11.11.0/lib/browser/math.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/alpinejs@3.x.x/dist/cdn.min.js" defer></script>
  <style>
    body {
      font-family: sans-serif;
      padding: 1rem;
    }
    .bar {
      height: 24px;
      margin: 4px 0;
      background: #e0e0e0;
      position: relative;
    }
    .fill {
      height: 100%;
      background: steelblue;
      color: white;
      text-align: right;
      padding-right: 8px;
      white-space: nowrap;
      overflow: hidden;
      border-radius: 4px;
    }
  </style>
</head>
<body x-data="softmaxViz()">
  <h4>Effect of Lambda (λ) on Speaker Choice</h4>
  <p>Utility of "square": <strong>1.0</strong><br>
     Utility of "green": <strong>0.5</strong></p>
<p><label for="lambda">λ (Rationality parameter): <strong x-text="lambda"></strong></label>
<input id="lambda" type="range" min="0" max="10" step="0.1" x-model.number="lambda"></p>
  <div class="bar">
    <div class="fill" :style="{ width: (pSquare * 100).toFixed(1) + '%' }">
      <span x-text="'square: ' + (pSquare * 100).toFixed(1) + '%' "></span>
    </div>
  </div>
  <div class="bar">
    <div class="fill" :style="{ width: (pGreen * 100).toFixed(1) + '%' }">
      <span x-text="'green: ' + (pGreen * 100).toFixed(1) + '%' "></span>
    </div>
  </div>
  <script>
    function softmaxViz() {
      return {
        lambda: 1,
        uSquare: 1.0,
        uGreen: 0.5,
        get pSquare() {
          const num = Math.exp(this.lambda * this.uSquare);
          const denom = num + Math.exp(this.lambda * this.uGreen);
          return num / denom;
        },
        get pGreen() {
          const num = Math.exp(this.lambda * this.uGreen);
          const denom = Math.exp(this.lambda * this.uSquare) + num;
          return num / denom;
        }
      }
    }
  </script>
</body>
</html>
<hr>
<hr>
<h3 id="sources">Sources<a hidden class="anchor" aria-hidden="true" href="#sources">#</a></h3>
<p>Degen (2023), <a href="https://www.annualreviews.org/content/journals/10.1146/annurev-linguistics-031220-010811"><em>The Rational Speech Act Framework</em></a></p>
<p>Franke, M., &amp; Jäger, G. (2016). <a href="(https://www.degruyter.com/document/doi/10.1515/zfs-2016-0002/html?lang=en&amp;srsltid=AfmBOorsU5Gn-tQd3xJ7ka_Cl8OKh5eujrjBwscNJHTEkX9JFG2WF9rR)">Probabilistic pragmatics, or why Bayes’ rule is probably important for pragmatics</a>. <em>Zeitschrift für Sprachwissenschaft</em>, 35(1), 3 - 44.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="http://localhost:1313/">Jun Zhang</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
